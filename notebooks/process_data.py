import json
import re
import os

# --- C·∫§U H√åNH ---
INPUT_FILE = "google_books_1000.json"  # File g·ªëc crawl v·ªÅ
OUTPUT_FILE = "books_clean.json"       # File s·∫°ch sau khi x·ª≠ l√Ω

# Ch·ªâ ch·∫•p nh·∫≠n 2 ng√¥n ng·ªØ n√†y
ALLOWED_LANGUAGES = ["vi", "en"]

# ƒê·ªô d√†i t·ªëi thi·ªÉu c·ªßa t√≥m t·∫Øt (ng·∫Øn qu√° th√¨ kh√¥ng ƒë·ªß √Ω ƒë·ªÉ t·∫°o vector)
MIN_SUMMARY_LENGTH = 50 

def remove_html_tags(text):
    """X√≥a c√°c th·∫ª HTML r√°c th∆∞·ªùng g·∫∑p trong Google Books (nh∆∞ <p>, <b>, <br>)"""
    if not text: return ""
    clean = re.compile('<.*?>')
    text = re.sub(clean, '', text)
    # X√≥a kho·∫£ng tr·∫Øng th·ª´a (v√≠ d·ª•: "  xin   ch√†o " -> "xin ch√†o")
    return " ".join(text.split())

def process_books():
    if not os.path.exists(INPUT_FILE):
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y file '{INPUT_FILE}'. H√£y ch·∫°y crawl tr∆∞·ªõc!")
        return

    print(f"üìÇ ƒêang ƒë·ªçc d·ªØ li·ªáu th√¥ t·ª´: {INPUT_FILE}...")
    with open(INPUT_FILE, "r", encoding="utf-8") as f:
        raw_data = json.load(f)

    print(f"üìä T·ªïng s·ªë s√°ch ban ƒë·∫ßu: {len(raw_data)}")
    
    clean_data = []
    stats = {
        "no_summary": 0,
        "wrong_lang": 0,
        "duplicate": 0,
        "kept": 0
    }
    
    seen_ids = set()

    for book in raw_data:
        # 1. L·ªçc tr√πng l·∫∑p (D·ª±a tr√™n ID)
        if book["id"] in seen_ids:
            stats["duplicate"] += 1
            continue

        # 2. L·ªçc ng√¥n ng·ªØ
        # ƒê√¥i khi Google tr·∫£ v·ªÅ 'vie' thay v√¨ 'vi', ho·∫∑c 'eng' thay v√¨ 'en'. X·ª≠ l√Ω linh ho·∫°t:
        lang = book.get("language", "").lower()
        if lang not in ALLOWED_LANGUAGES:
            # Th·ª≠ map 'vie' -> 'vi', 'eng' -> 'en' n·∫øu c·∫ßn, nh∆∞ng th∆∞·ªùng Google tr·∫£ v·ªÅ m√£ chu·∫©n 2 k√Ω t·ª±
            stats["wrong_lang"] += 1
            continue

        # 3. L·ªçc & L√†m s·∫°ch T√≥m t·∫Øt (Summary)
        raw_summary = book.get("summary", "")
        clean_summary = remove_html_tags(raw_summary)

        if not clean_summary or len(clean_summary) < MIN_SUMMARY_LENGTH:
            stats["no_summary"] += 1
            continue

        # 4. Chu·∫©n h√≥a c√°c tr∆∞·ªùng kh√°c
        clean_book = {
            "id": book["id"],
            "title": remove_html_tags(book.get("title", "No Title")),
            "author": remove_html_tags(book.get("author", "Unknown")),
            "genre": book.get("genre", "General"),
            "language": lang,
            "summary": clean_summary, # D√πng b·∫£n ƒë√£ l√†m s·∫°ch
            "year": book.get("published_date", "")[:4], # Ch·ªâ l·∫•y nƒÉm
            "page_count": book.get("page_count", 0)
        }

        clean_data.append(clean_book)
        seen_ids.add(book["id"])
        stats["kept"] += 1

    # L∆∞u file k·∫øt qu·∫£
    with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
        json.dump(clean_data, f, indent=4, ensure_ascii=False)

    print("\n" + "="*40)
    print("üßπ K·∫æT QU·∫¢ X·ª¨ L√ù D·ªÆ LI·ªÜU")
    print("="*40)
    print(f"‚ùå Lo·∫°i b·ªè (Sai ng√¥n ng·ªØ):   {stats['wrong_lang']}")
    print(f"‚ùå Lo·∫°i b·ªè (Kh√¥ng m√¥ t·∫£):    {stats['no_summary']}")
    print(f"‚ùå Lo·∫°i b·ªè (Tr√πng l·∫∑p):      {stats['duplicate']}")
    print("-" * 40)
    print(f"‚úÖ S√ÅCH S·∫†CH ƒê∆Ø·ª¢C GI·ªÆ L·∫†I:  {len(clean_data)}")
    print(f"üíæ ƒê√£ l∆∞u t·∫°i:               {OUTPUT_FILE}")
    print("="*40)
    print("\nüëâ B∆∞·ªõc ti·∫øp theo: V√†o 'src/ingest.py' s·ª≠a DATA_FILE = 'books_clean.json'")

if __name__ == "__main__":
    process_books()