{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33dc1e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: qdrant_client in /home/khoi/miniconda3/envs/RAG/lib/python3.14/site-packages (1.16.2)\n",
      "Requirement already satisfied: neo4j in /home/khoi/miniconda3/envs/RAG/lib/python3.14/site-packages (6.0.3)\n",
      "Requirement already satisfied: grpcio>=1.41.0 in /home/khoi/miniconda3/envs/RAG/lib/python3.14/site-packages (from qdrant_client) (1.76.0)\n",
      "Requirement already satisfied: httpx>=0.20.0 in /home/khoi/miniconda3/envs/RAG/lib/python3.14/site-packages (from httpx[http2]>=0.20.0->qdrant_client) (0.28.1)\n",
      "Requirement already satisfied: numpy>=2.3.0 in /home/khoi/miniconda3/envs/RAG/lib/python3.14/site-packages (from qdrant_client) (2.4.0)\n",
      "Requirement already satisfied: portalocker<4.0,>=2.7.0 in /home/khoi/miniconda3/envs/RAG/lib/python3.14/site-packages (from qdrant_client) (3.2.0)\n",
      "Requirement already satisfied: protobuf>=3.20.0 in /home/khoi/miniconda3/envs/RAG/lib/python3.14/site-packages (from qdrant_client) (5.29.5)\n",
      "Requirement already satisfied: pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8 in /home/khoi/miniconda3/envs/RAG/lib/python3.14/site-packages (from qdrant_client) (2.12.5)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.14 in /home/khoi/miniconda3/envs/RAG/lib/python3.14/site-packages (from qdrant_client) (2.6.2)\n",
      "Requirement already satisfied: pytz in /home/khoi/miniconda3/envs/RAG/lib/python3.14/site-packages (from neo4j) (2025.2)\n",
      "Requirement already satisfied: typing-extensions~=4.12 in /home/khoi/miniconda3/envs/RAG/lib/python3.14/site-packages (from grpcio>=1.41.0->qdrant_client) (4.15.0)\n",
      "Requirement already satisfied: anyio in /home/khoi/miniconda3/envs/RAG/lib/python3.14/site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (4.12.0)\n",
      "Requirement already satisfied: certifi in /home/khoi/miniconda3/envs/RAG/lib/python3.14/site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /home/khoi/miniconda3/envs/RAG/lib/python3.14/site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (1.0.9)\n",
      "Requirement already satisfied: idna in /home/khoi/miniconda3/envs/RAG/lib/python3.14/site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /home/khoi/miniconda3/envs/RAG/lib/python3.14/site-packages (from httpcore==1.*->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (0.16.0)\n",
      "Requirement already satisfied: h2<5,>=3 in /home/khoi/miniconda3/envs/RAG/lib/python3.14/site-packages (from httpx[http2]>=0.20.0->qdrant_client) (4.3.0)\n",
      "Requirement already satisfied: hyperframe<7,>=6.1 in /home/khoi/miniconda3/envs/RAG/lib/python3.14/site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant_client) (6.1.0)\n",
      "Requirement already satisfied: hpack<5,>=4.1 in /home/khoi/miniconda3/envs/RAG/lib/python3.14/site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant_client) (4.1.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/khoi/miniconda3/envs/RAG/lib/python3.14/site-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant_client) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /home/khoi/miniconda3/envs/RAG/lib/python3.14/site-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant_client) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /home/khoi/miniconda3/envs/RAG/lib/python3.14/site-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant_client) (0.4.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install qdrant_client neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e864e027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log file deleted, please re-run the main script!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if os.path.exists('processed_ids.log'):\n",
    "    os.remove('processed_ids.log')\n",
    "print(\"Log file deleted, please re-run the main script!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88288d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Credentials loaded from environment\n"
     ]
    }
   ],
   "source": [
    "# Load credentials t·ª´ environment ho·∫∑c .env file\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Credentials (n·∫øu kh√¥ng c√≥ trong env, s·∫Ω d√πng default)\n",
    "TMDB_API_KEY = os.getenv('TMDB_API_KEY', 'ba39c73252cd9fb0849949da47454e7d')\n",
    "QDRANT_URL = os.getenv('QDRANT_URL', 'https://9a823e32-f097-4096-87a0-23f05baaf13a.europe-west3-0.gcp.cloud.qdrant.io')\n",
    "QDRANT_API_KEY = os.getenv('QDRANT_API_KEY', 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3MiOiJtIn0.yZ1QMZ7exqzs_wswtYsqtwaGpu2ExXfhltpNwUq8Zp0')\n",
    "NEO4J_URI = os.getenv('NEO4J_URI', 'neo4j+s://294ac027.databases.neo4j.io')\n",
    "NEO4J_USERNAME = os.getenv('NEO4J_USER', 'neo4j')\n",
    "NEO4J_PASSWORD = os.getenv('NEO4J_PASSWORD', 'HCF2K8_WnovcGqSKeNocCRi_7upAxqqeTAfTDMCSAjM')\n",
    "\n",
    "print(\"‚úÖ Credentials loaded from environment\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52151bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üîç TESTING DATABASE CONNECTIONS\n",
      "======================================================================\n",
      "\n",
      "1Ô∏è‚É£ Testing Qdrant Cloud...\n",
      "   ‚úÖ Connected! Found 3 collection(s)\n",
      "\n",
      "2Ô∏è‚É£ Testing Neo4j...\n",
      "   ‚úÖ Connected! Test query returned: 1\n",
      "\n",
      "3Ô∏è‚É£ Testing TMDB API...\n",
      "   ‚úÖ Connected! Test movie: Fight Club\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# üîç Troubleshooting: Test all connections\n",
    "print(\"=\" * 70)\n",
    "print(\"üîç TESTING DATABASE CONNECTIONS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Test 1: Qdrant\n",
    "print(\"\\n1Ô∏è‚É£ Testing Qdrant Cloud...\")\n",
    "try:\n",
    "    from qdrant_client import QdrantClient\n",
    "    test_client = QdrantClient(url=QDRANT_URL, api_key=QDRANT_API_KEY, timeout=10, prefer_grpc=False)\n",
    "    collections = test_client.get_collections()\n",
    "    print(f\"   ‚úÖ Connected! Found {len(collections.collections)} collection(s)\")\n",
    "except Exception as e:\n",
    "    print(f\"   ‚ùå Failed: {str(e)[:150]}\")\n",
    "    print(\"   üí° Tip: Check Qdrant dashboard - cluster might be paused\")\n",
    "\n",
    "# Test 2: Neo4j\n",
    "print(\"\\n2Ô∏è‚É£ Testing Neo4j...\")\n",
    "try:\n",
    "    from neo4j import GraphDatabase\n",
    "    test_driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD))\n",
    "    with test_driver.session() as session:\n",
    "        result = session.run(\"RETURN 1 as test\")\n",
    "        print(f\"   ‚úÖ Connected! Test query returned: {result.single()['test']}\")\n",
    "    test_driver.close()\n",
    "except Exception as e:\n",
    "    print(f\"   ‚ùå Failed: {str(e)[:150]}\")\n",
    "    print(\"   üí° Tip: Check Neo4j Aura console - instance might be stopped\")\n",
    "\n",
    "# Test 3: TMDB API\n",
    "print(\"\\n3Ô∏è‚É£ Testing TMDB API...\")\n",
    "try:\n",
    "    import requests\n",
    "    resp = requests.get(f\"https://api.themoviedb.org/3/movie/550?api_key={TMDB_API_KEY}\")\n",
    "    if resp.status_code == 200:\n",
    "        movie = resp.json()\n",
    "        print(f\"   ‚úÖ Connected! Test movie: {movie['title']}\")\n",
    "    else:\n",
    "        print(f\"   ‚ùå Failed: Status {resp.status_code}\")\n",
    "except Exception as e:\n",
    "    print(f\"   ‚ùå Failed: {str(e)[:150]}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3cb485d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Qdrant Connected Successfully!\n",
      "\n",
      "üì¶ Found 3 collection(s):\n",
      "\n",
      "  üìÅ books_collection\n",
      "     Points: 0\n",
      "\n",
      "  üìÅ movies_vietnamese\n",
      "     Points: 865\n",
      "\n",
      "  üìÅ movies_graph_rag\n",
      "     Points: 0\n"
     ]
    }
   ],
   "source": [
    "# Quick test: Check Qdrant connection\n",
    "from qdrant_client import QdrantClient\n",
    "\n",
    "try:\n",
    "    # Add timeout and use REST API\n",
    "    qdrant_client = QdrantClient(\n",
    "        url=QDRANT_URL, \n",
    "        api_key=QDRANT_API_KEY,\n",
    "        timeout=10,\n",
    "        prefer_grpc=False\n",
    "    )\n",
    "    \n",
    "    # Test connection\n",
    "    collections = qdrant_client.get_collections()\n",
    "    print(\"‚úÖ Qdrant Connected Successfully!\")\n",
    "    print(f\"\\nüì¶ Found {len(collections.collections)} collection(s):\")\n",
    "    \n",
    "    if collections.collections:\n",
    "        for coll in collections.collections:\n",
    "            # Get detailed info for each collection\n",
    "            try:\n",
    "                info = qdrant_client.get_collection(coll.name)\n",
    "                # Access counts correctly based on API version\n",
    "                vectors_count = info.vectors_count if hasattr(info, 'vectors_count') else info.points_count\n",
    "                points_count = info.points_count if hasattr(info, 'points_count') else 0\n",
    "                \n",
    "                print(f\"\\n  üìÅ {coll.name}\")\n",
    "                print(f\"     Points: {points_count:,}\")\n",
    "                if hasattr(info, 'vectors_count'):\n",
    "                    print(f\"     Vectors: {vectors_count:,}\")\n",
    "            except Exception as e:\n",
    "                print(f\"\\n  üìÅ {coll.name} (details unavailable)\")\n",
    "    else:\n",
    "        print(\"\\n  (No collections yet - ready to create)\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(\"‚ùå Cannot connect to Qdrant Cloud\")\n",
    "    print(f\"\\nError details: {str(e)[:250]}\")\n",
    "    print(\"\\nüí° Common issues:\")\n",
    "    print(\"  1. Cluster paused (free tier auto-pauses after inactivity)\")\n",
    "    print(\"  2. API key expired or revoked\")\n",
    "    print(\"  3. URL incorrect (check Qdrant dashboard)\")\n",
    "    print(\"  4. Network/firewall blocking port 6333\")\n",
    "    print(\"\\nüîß Quick fixes:\")\n",
    "    print(\"  ‚Ä¢ Visit: https://cloud.qdrant.io/\")\n",
    "    print(\"  ‚Ä¢ Resume your cluster if paused\")\n",
    "    print(\"  ‚Ä¢ Or use local Qdrant: QdrantClient(path='./qdrant_local')\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a379316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üöÄ ENHANCED DATA CRAWL PIPELINE (GEMINI EMBEDDINGS)\n",
      "================================================================================\n",
      "\n",
      "‚öôÔ∏è  Configuration:\n",
      "   ‚Ä¢ Batch size: 25\n",
      "   ‚Ä¢ Total strategies: 2\n",
      "   ‚Ä¢ Expected total movies: ~700\n",
      "   ‚Ä¢ Quality filters: votes>=100, rating>=5.0\n",
      "   ‚Ä¢ Embedding: Gemini text-embedding-004 (768 dims)\n",
      "   ‚Ä¢ Embedding timeout: 30s (‚ö° auto-kill n·∫øu treo)\n",
      "   ‚Ä¢ Neo4j: ‚úÖ Enabled\n",
      "   ‚Ä¢ üÜï Local save: ‚úÖ Enabled\n",
      "   ‚Ä¢ üìÅ Save location: ../crawled_data/\n",
      "\n",
      "‚è≥ Initializing connections...\n",
      "\n",
      "‚úÖ Created local data directories: ../crawled_data/\n",
      "   ‚Ä¢ movies/ - JSON data files\n",
      "   ‚Ä¢ posters/ - Poster URLs\n",
      "\n",
      "‚úÖ Qdrant connected\n",
      "‚úÖ Collection 'movies_vietnamese' exists\n",
      "‚è≥ Configuring Gemini embedding model...\n",
      "‚úÖ Gemini embedding configured\n",
      "‚úÖ Neo4j connected\n",
      "\n",
      "üìã Already processed: 606 movies\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üéØ STRATEGY: Popular\n",
      "================================================================================\n",
      "üîç Discovering movies...\n",
      "‚úÖ Found 400 candidate movies\n",
      "\n",
      "üì• New movies to process: 20\n",
      "\n",
      "\n",
      "üîÑ Batch 1/1...\n",
      "   ‚úÖ Bugonia (10 cast, 15 kw, 1 sim)\n",
      "   ‚úÖ The Dead (10 cast, 4 kw, 4 sim)\n",
      "   ‚úÖ Labor Day (10 cast, 15 kw, 4 sim)\n",
      "   ‚úÖ The Naked Gun (10 cast, 9 kw, 2 sim)\n",
      "   ‚úÖ Thunderbolts* (10 cast, 15 kw, 2 sim)\n",
      "   ‚úÖ Captain America: Brave New World (10 cast, 13 kw, 2 sim)\n",
      "   ‚úÖ Godzilla x Kong: The New Empire (10 cast, 12 kw, 4 sim)\n",
      "   ‚úÖ Swing Girls (10 cast, 9 kw, 3 sim)\n",
      "   ‚úÖ The Monuments Men (10 cast, 5 kw, 2 sim)\n",
      "   ‚úÖ The Tomorrow War (10 cast, 15 kw, 2 sim)\n",
      "   ‚úÖ The Smashing Machine (10 cast, 10 kw, 5 sim)\n",
      "   ‚úÖ Flight Risk (10 cast, 8 kw, 4 sim)\n",
      "   ‚úÖ The Little Mermaid (10 cast, 5 kw, 4 sim)\n",
      "   ‚úÖ The Witch: Part 2. The Other One (10 cast, 2 kw, 4 sim)\n",
      "   ‚úÖ Her (10 cast, 15 kw, 1 sim)\n",
      "   ‚úÖ Colombiana (10 cast, 4 kw, 2 sim)\n",
      "   ‚úÖ Solo Leveling -ReAwakening- (8 cast, 8 kw, 2 sim)\n",
      "   ‚úÖ The Running Man (10 cast, 15 kw, 2 sim)\n",
      "   ‚úÖ Elemental (10 cast, 11 kw, 5 sim)\n",
      "   ‚úÖ Nobody (10 cast, 11 kw, 5 sim)\n",
      "   üìä Batch result: 20/20 successful\n",
      "\n",
      "================================================================================\n",
      "üéØ STRATEGY: Top Rated\n",
      "================================================================================\n",
      "üîç Discovering movies...\n",
      "‚úÖ Found 299 candidate movies\n",
      "\n",
      "üì• New movies to process: 28\n",
      "\n",
      "\n",
      "üîÑ Batch 1/2...\n",
      "   ‚úÖ Gabriel's Inferno: Part II (9 cast, 1 kw, 3 sim)\n",
      "   ‚úÖ Stalker (9 cast, 11 kw, 3 sim)\n",
      "   ‚úÖ 1987: When the Day Comes (10 cast, 11 kw, 5 sim)\n",
      "   ‚úÖ Wonder (10 cast, 11 kw, 5 sim)\n",
      "   ‚úÖ Senna (10 cast, 15 kw, 3 sim)\n",
      "   ‚úÖ Portrait of a Lady on Fire (8 cast, 15 kw, 3 sim)\n",
      "   ‚úÖ Incendies (10 cast, 15 kw, 1 sim)\n",
      "   ‚úÖ Double Indemnity (10 cast, 11 kw, 3 sim)\n",
      "   ‚úÖ Ya veremos (10 cast, 0 kw, 0 sim)\n",
      "   ‚úÖ Avicii - I'm Tim (10 cast, 9 kw, 3 sim)\n",
      "   ‚úÖ Kally‚Äôs Mashup: A Very Kally's Birthday (8 cast, 1 kw, 0 sim)\n",
      "   ‚úÖ Lock, Stock and Two Smoking Barrels (10 cast, 15 kw, 5 sim)\n",
      "   ‚úÖ Metropolis (10 cast, 15 kw, 2 sim)\n",
      "   ‚úÖ Isle of Flowers (10 cast, 14 kw, 0 sim)\n",
      "   ‚úÖ Sube y baja (10 cast, 4 kw, 4 sim)\n",
      "   ‚úÖ Zack Snyder's Justice League (10 cast, 9 kw, 5 sim)\n",
      "   ‚úÖ Violet Evergarden: Eternity and the Auto Memory Doll (10 cast, 12 kw, 1 sim)\n",
      "   ‚úÖ Prisoners (10 cast, 15 kw, 3 sim)\n",
      "   ‚úÖ Soul (10 cast, 12 kw, 5 sim)\n",
      "   ‚úÖ Call Me by Your Name (10 cast, 15 kw, 3 sim)\n",
      "   ‚úÖ ‚ÄúThe Shorts‚Äù by Aldo, Giovanni and Giacomo (4 cast, 0 kw, 5 sim)\n",
      "   ‚úÖ Satantango (10 cast, 15 kw, 3 sim)\n",
      "   ‚úÖ Cardcaptor Sakura: The Sealed Card (10 cast, 10 kw, 2 sim)\n",
      "   ‚úÖ The Father (8 cast, 15 kw, 4 sim)\n",
      "   ‚úÖ The Hunt (10 cast, 15 kw, 0 sim)\n",
      "   üìä Batch result: 25/25 successful\n",
      "\n",
      "üîÑ Batch 2/2...\n",
      "   ‚úÖ Wild Strawberries (10 cast, 11 kw, 3 sim)\n",
      "   ‚úÖ A Dog Named Palma (10 cast, 0 kw, 0 sim)\n",
      "   ‚úÖ In the Mood for Love (10 cast, 15 kw, 5 sim)\n",
      "   üìä Batch result: 3/3 successful\n",
      "\n",
      "================================================================================\n",
      "üéâ CRAWL COMPLETE!\n",
      "================================================================================\n",
      "\n",
      "üìä Statistics:\n",
      "   ‚Ä¢ Total discovered: 699\n",
      "   ‚Ä¢ Successfully processed: 48\n",
      "   ‚Ä¢ Failed: 0\n",
      "   ‚Ä¢ Success rate: 6.9%\n",
      "\n",
      "üìÅ Local Data Saved:\n",
      "   ‚Ä¢ Location: ../crawled_data/\n",
      "   ‚Ä¢ Movies JSON: ../crawled_data/movies/\n",
      "   ‚Ä¢ Poster URLs: ../crawled_data/posters/\n",
      "\n",
      "‚úÖ Created index file: ../crawled_data/movies_index.json\n",
      "   ‚Ä¢ Contains 654 movies\n",
      "   ‚Ä¢ Sorted by rating (highest first)\n",
      "\n",
      "üí° Use this index for UI/UX development!\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Script ch√≠nh: Crawl TMDB -> Upload Qdrant + Neo4j (ENHANCED VERSION)\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "from typing import List, Dict\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import PointStruct, VectorParams, Distance\n",
    "# OLD: SentenceTransformer (comment out - causes mismatch)\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "# NEW: Use Gemini\n",
    "import google.generativeai as genai\n",
    "from neo4j import GraphDatabase\n",
    "import random\n",
    "\n",
    "# ==========================================\n",
    "# 1. CONFIGURATION (TUNED FOR BETTER DATA)\n",
    "# ==========================================\n",
    "\n",
    "BASE_URL = 'https://api.themoviedb.org/3'\n",
    "COLLECTION_NAME = \"movies_vietnamese\"\n",
    "\n",
    "# BATCH & PAGINATION - Optimized for SPEED\n",
    "BATCH_SIZE = 25  # ‚Üë Increased to 25 for faster processing\n",
    "MAX_PAGES = 60   # ‚Üë Increased from 10 -> 50 (1000 movies instead of 200)\n",
    "PROCESSED_FILE = 'processed_ids.log'\n",
    "ENABLE_NEO4J = True  # ‚ö° Disable Neo4j to speed up 3-5x (vector search only)\n",
    "EMBEDDING_TIMEOUT = 30  # ‚ö° Timeout for each embedding call (seconds)\n",
    "\n",
    "# üÜï LOCAL STORAGE - Save data before uploading to DBs\n",
    "SAVE_LOCAL_DATA = True  # Save to JSON files first\n",
    "LOCAL_DATA_DIR = '../crawled_data'  # Folder to save data\n",
    "POSTER_BASE_URL = 'https://image.tmdb.org/t/p/w500'  # TMDB poster URL\n",
    "\n",
    "# QUALITY FILTERS - Ensure good data\n",
    "MIN_VOTE_COUNT = 100  # Only get movies with >= 100 votes (popular enough)\n",
    "MIN_RATING = 5.0      # Rating >= 5.0 (reasonable quality)\n",
    "MIN_OVERVIEW_LENGTH = 50  # Overview must have >= 50 chars\n",
    "\n",
    "# DIVERSITY STRATEGIES - Multiple discovery methods\n",
    "DISCOVERY_STRATEGIES = [\n",
    "    # Strategy 1: Popular movies (FAST MODE - reduced pages)\n",
    "    {\n",
    "        'name': 'Popular',\n",
    "        'params': {\n",
    "            'sort_by': 'popularity.desc',\n",
    "            'vote_count.gte': MIN_VOTE_COUNT,\n",
    "            'vote_average.gte': MIN_RATING\n",
    "        },\n",
    "        'pages': 20  # ‚ö° Reduced from 20 -> 10 for quick testing\n",
    "    },\n",
    "    # Strategy 2: Top rated\n",
    "    {\n",
    "        'name': 'Top Rated',\n",
    "        'params': {\n",
    "            'sort_by': 'vote_average.desc',\n",
    "            'vote_count.gte': MIN_VOTE_COUNT,\n",
    "            'vote_average.gte': 7.0\n",
    "        },\n",
    "        'pages': 15  # ‚ö° Reduced from 15 -> 5\n",
    "    }\n",
    "]\n",
    "\n",
    "# ==========================================\n",
    "# 2. INITIALIZE CONNECTIONS\n",
    "# ==========================================\n",
    "print(\"=\" * 80)\n",
    "print(\"üöÄ ENHANCED DATA CRAWL PIPELINE (GEMINI EMBEDDINGS)\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\n‚öôÔ∏è  Configuration:\")\n",
    "print(f\"   ‚Ä¢ Batch size: {BATCH_SIZE}\")\n",
    "print(f\"   ‚Ä¢ Total strategies: {len(DISCOVERY_STRATEGIES)}\")\n",
    "print(f\"   ‚Ä¢ Expected total movies: ~{sum(s['pages'] * 20 for s in DISCOVERY_STRATEGIES)}\")\n",
    "print(f\"   ‚Ä¢ Quality filters: votes>={MIN_VOTE_COUNT}, rating>={MIN_RATING}\")\n",
    "print(f\"   ‚Ä¢ Embedding: Gemini text-embedding-004 (768 dims)\")\n",
    "print(f\"   ‚Ä¢ Embedding timeout: {EMBEDDING_TIMEOUT}s (‚ö° auto-kill n·∫øu treo)\")\n",
    "print(f\"   ‚Ä¢ Neo4j: {'‚úÖ Enabled' if ENABLE_NEO4J else '‚ö° DISABLED (fast mode)'}\")\n",
    "print(f\"   ‚Ä¢ üÜï Local save: {'‚úÖ Enabled' if SAVE_LOCAL_DATA else '‚ùå Disabled'}\")\n",
    "if SAVE_LOCAL_DATA:\n",
    "    print(f\"   ‚Ä¢ üìÅ Save location: {LOCAL_DATA_DIR}/\")\n",
    "print(\"\\n‚è≥ Initializing connections...\\n\")\n",
    "\n",
    "# Create local data directories if needed\n",
    "if SAVE_LOCAL_DATA:\n",
    "    import os\n",
    "    os.makedirs(LOCAL_DATA_DIR, exist_ok=True)\n",
    "    os.makedirs(f\"{LOCAL_DATA_DIR}/movies\", exist_ok=True)\n",
    "    os.makedirs(f\"{LOCAL_DATA_DIR}/posters\", exist_ok=True)\n",
    "    print(f\"‚úÖ Created local data directories: {LOCAL_DATA_DIR}/\")\n",
    "    print(f\"   ‚Ä¢ movies/ - JSON data files\")\n",
    "    print(f\"   ‚Ä¢ posters/ - Poster URLs\\n\")\n",
    "\n",
    "# Qdrant & Embedding Model\n",
    "try:\n",
    "    q_client = QdrantClient(\n",
    "        url=QDRANT_URL, \n",
    "        api_key=QDRANT_API_KEY,\n",
    "        timeout=30,\n",
    "        prefer_grpc=False\n",
    "    )\n",
    "    \n",
    "    # Test connection\n",
    "    q_client.get_collections()\n",
    "    print(\"‚úÖ Qdrant connected\")\n",
    "    \n",
    "    if not q_client.collection_exists(COLLECTION_NAME):\n",
    "        q_client.create_collection(\n",
    "            collection_name=COLLECTION_NAME,\n",
    "            vectors_config=VectorParams(size=768, distance=Distance.COSINE),\n",
    "        )\n",
    "        print(f\"‚úÖ Created collection '{COLLECTION_NAME}'\")\n",
    "    else:\n",
    "        print(f\"‚úÖ Collection '{COLLECTION_NAME}' exists\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Qdrant connection failed: {e}\")\n",
    "    print(\"‚ö†Ô∏è Script will continue but won't upload to Qdrant\")\n",
    "    q_client = None\n",
    "\n",
    "# OLD: SentenceTransformer Embedding Model (comment out)\n",
    "# print(\"‚è≥ Loading embedding model...\")\n",
    "# embed_model = SentenceTransformer('paraphrase-multilingual-mpnet-base-v2')\n",
    "# print(\"‚úÖ Embedding model loaded\")\n",
    "\n",
    "# NEW: Gemini Embedding Model\n",
    "print(\"‚è≥ Configuring Gemini embedding model...\")\n",
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\",\"AIzaSyDb3B5gPGV8pGgHFBmwEC4XwfzmBgnJCW0\" ))\n",
    "print(\"‚úÖ Gemini embedding configured\")\n",
    "\n",
    "# Helper function for Gemini embedding v·ªõi TIMEOUT (fix treo)\n",
    "def get_gemini_embedding(text, task_type=\"retrieval_document\", max_retries=3, timeout=30):\n",
    "    \"\"\"\n",
    "    Get embedding from Gemini with TIMEOUT to prevent hanging\n",
    "    \"\"\"\n",
    "    import signal\n",
    "    from functools import wraps\n",
    "    \n",
    "    # Truncate text if too long\n",
    "    if len(text) > 5000:\n",
    "        text = text[:5000]\n",
    "    \n",
    "    def timeout_handler(signum, frame):\n",
    "        raise TimeoutError(\"API call exceeded timeout\")\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            # Set alarm signal for timeout\n",
    "            signal.signal(signal.SIGALRM, timeout_handler)\n",
    "            signal.alarm(timeout)  # ‚ö° Kill request sau 30s\n",
    "            \n",
    "            try:\n",
    "                result = genai.embed_content(\n",
    "                    model=\"models/text-embedding-004\",\n",
    "                    content=text,\n",
    "                    task_type=task_type\n",
    "                )\n",
    "                signal.alarm(0)  # Cancel alarm n·∫øu th√†nh c√¥ng\n",
    "                return result['embedding']\n",
    "                \n",
    "            finally:\n",
    "                signal.alarm(0)  # Always cancel alarm\n",
    "                \n",
    "        except TimeoutError:\n",
    "            print(f\"      ‚è±Ô∏è  Timeout sau {timeout}s (attempt {attempt + 1}/{max_retries})\")\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(2)\n",
    "                \n",
    "        except Exception as e:\n",
    "            error_msg = str(e).lower()\n",
    "            \n",
    "            # Rate limit\n",
    "            if \"429\" in error_msg or \"rate limit\" in error_msg or \"quota\" in error_msg:\n",
    "                wait = min(5 * (attempt + 1), 20)\n",
    "                print(f\"      ‚è≥ Rate limited, waiting {wait}s...\")\n",
    "                time.sleep(wait)\n",
    "                \n",
    "            # Server error\n",
    "            elif \"500\" in error_msg or \"503\" in error_msg:\n",
    "                wait = 2 * (attempt + 1)\n",
    "                print(f\"      ‚ö†Ô∏è  Server error, waiting {wait}s...\")\n",
    "                time.sleep(wait)\n",
    "                \n",
    "            # Unknown error - kh√¥ng retry\n",
    "            else:\n",
    "                print(f\"      ‚ùå Error: {str(e)[:100]}\")\n",
    "                return None\n",
    "    \n",
    "    print(f\"      ‚ùå Failed sau {max_retries} attempts\")\n",
    "    return None\n",
    "# Neo4j Driver (optional - skip if ENABLE_NEO4J = False)\n",
    "if ENABLE_NEO4J:\n",
    "    try:\n",
    "        n_driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD))\n",
    "        # Test connection\n",
    "        with n_driver.session() as session:\n",
    "            session.run(\"RETURN 1\")\n",
    "        print(\"‚úÖ Neo4j connected\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Neo4j connection failed: {e}\")\n",
    "        print(\"‚ö†Ô∏è Script will continue but won't upload to Neo4j\")\n",
    "        n_driver = None\n",
    "else:\n",
    "    n_driver = None\n",
    "    print(\"‚ö° Neo4j SKIPPED (fast mode - vector search only)\\n\")\n",
    "# ==========================================\n",
    "# ==========================================\n",
    "# 3. DATA PREPROCESSING & CLEANING FUNCTIONS\n",
    "# ==========================================\n",
    "\n",
    "import re\n",
    "import unicodedata\n",
    "from html import unescape\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Clean and normalize text for better quality\"\"\"\n",
    "    if not text or not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # Decode HTML entities\n",
    "    text = unescape(text)\n",
    "    \n",
    "    # Normalize unicode characters\n",
    "    text = unicodedata.normalize('NFKD', text)\n",
    "    \n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<[^>]+>', '', text)\n",
    "    \n",
    "    # Normalize whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Remove leading/trailing whitespace\n",
    "    text = text.strip()\n",
    "    \n",
    "    # Remove control characters but keep newlines\n",
    "    text = ''.join(char for char in text if char == '\\n' or not unicodedata.category(char).startswith('C'))\n",
    "    \n",
    "    return text\n",
    "\n",
    "def normalize_person_name(name):\n",
    "    \"\"\"Standardize person names for consistency\"\"\"\n",
    "    if not name or not isinstance(name, str):\n",
    "        return None\n",
    "    \n",
    "    # Clean text\n",
    "    name = clean_text(name)\n",
    "    \n",
    "    # Remove common suffixes\n",
    "    suffixes = [' Jr.', ' Sr.', ' III', ' II', ' IV', ' Jr', ' Sr']\n",
    "    for suffix in suffixes:\n",
    "        if name.endswith(suffix):\n",
    "            name = name[:-len(suffix)].strip()\n",
    "    \n",
    "    # Title case (but preserve all-caps acronyms)\n",
    "    if not name.isupper() or len(name) <= 3:\n",
    "        name = name.title()\n",
    "    \n",
    "    # Handle special cases\n",
    "    name = name.replace(\"'S\", \"'s\")  # McDonald's not McDonald'S\n",
    "    \n",
    "    return name.strip()\n",
    "\n",
    "def normalize_title(title):\n",
    "    \"\"\"Normalize movie titles\"\"\"\n",
    "    if not title or not isinstance(title, str):\n",
    "        return None\n",
    "    \n",
    "    # Clean text\n",
    "    title = clean_text(title)\n",
    "    \n",
    "    # Normalize common patterns\n",
    "    # \"The Dark Knight, The\" ‚Üí \"The Dark Knight\"\n",
    "    if ', The' in title:\n",
    "        title = 'The ' + title.replace(', The', '')\n",
    "    elif ', A' in title:\n",
    "        title = 'A ' + title.replace(', A', '')\n",
    "    \n",
    "    return title.strip()\n",
    "\n",
    "def validate_tmdb_id(tmdb_id):\n",
    "    \"\"\"Validate TMDB ID\"\"\"\n",
    "    if not tmdb_id:\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        tmdb_id = int(tmdb_id)\n",
    "        return tmdb_id > 0\n",
    "    except (ValueError, TypeError):\n",
    "        return False\n",
    "\n",
    "def deduplicate_list(items, key=None):\n",
    "    \"\"\"Remove duplicates while preserving order\"\"\"\n",
    "    if not items:\n",
    "        return []\n",
    "    \n",
    "    seen = set()\n",
    "    result = []\n",
    "    \n",
    "    for item in items:\n",
    "        # Get comparison key\n",
    "        if key:\n",
    "            compare_val = key(item) if callable(key) else item.get(key) if isinstance(item, dict) else item\n",
    "        else:\n",
    "            compare_val = item\n",
    "        \n",
    "        # Skip if seen\n",
    "        if compare_val in seen:\n",
    "            continue\n",
    "        \n",
    "        seen.add(compare_val)\n",
    "        result.append(item)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def clean_keyword(keyword):\n",
    "    \"\"\"Clean and normalize keywords\"\"\"\n",
    "    if not keyword or not isinstance(keyword, str):\n",
    "        return None\n",
    "    \n",
    "    # Clean text\n",
    "    keyword = clean_text(keyword)\n",
    "    \n",
    "    # Lowercase for keywords\n",
    "    keyword = keyword.lower()\n",
    "    \n",
    "    # Remove common stop words from compound keywords\n",
    "    stop_words = ['the', 'a', 'an']\n",
    "    words = keyword.split()\n",
    "    if len(words) > 1 and words[0] in stop_words:\n",
    "        keyword = ' '.join(words[1:])\n",
    "    \n",
    "    return keyword.strip()\n",
    "\n",
    "def validate_movie_data(movie_data):\n",
    "    \"\"\"Validate movie data quality\"\"\"\n",
    "    if not movie_data:\n",
    "        return False, \"No data\"\n",
    "    \n",
    "    movie = movie_data.get('movie', {})\n",
    "    \n",
    "    # Required fields\n",
    "    if not movie.get('id'):\n",
    "        return False, \"Missing movie ID\"\n",
    "    \n",
    "    if not movie.get('title'):\n",
    "        return False, \"Missing title\"\n",
    "    \n",
    "    overview = movie.get('overview', '').strip()\n",
    "    if not overview or len(overview) < 20:\n",
    "        return False, \"Overview too short or missing\"\n",
    "    \n",
    "    # Quality checks\n",
    "    if movie.get('vote_count', 0) < MIN_VOTE_COUNT:\n",
    "        return False, f\"Too few votes ({movie.get('vote_count', 0)})\"\n",
    "    \n",
    "    if movie.get('vote_average', 0) < MIN_RATING:\n",
    "        return False, f\"Rating too low ({movie.get('vote_average', 0)})\"\n",
    "    \n",
    "    return True, \"Valid\"\n",
    "\n",
    "def create_optimized_embedding_text(movie, cast, keywords, directors):\n",
    "    \"\"\"Create optimized text for embedding with proper preprocessing\"\"\"\n",
    "    parts = []\n",
    "    \n",
    "    # Title (cleaned)\n",
    "    title = normalize_title(movie.get('title', ''))\n",
    "    if title:\n",
    "        parts.append(f\"Title: {title}\")\n",
    "    \n",
    "    # Genres\n",
    "    genres = [clean_text(g['name']) for g in movie.get('genres', [])]\n",
    "    if genres:\n",
    "        parts.append(f\"Genres: {', '.join(genres)}\")\n",
    "    \n",
    "    # Overview (cleaned and truncated)\n",
    "    overview = clean_text(movie.get('overview', ''))\n",
    "    if overview:\n",
    "        overview = overview[:2000] if len(overview) > 2000 else overview\n",
    "        parts.append(f\"Overview: {overview}\")\n",
    "    \n",
    "    # Tagline (if meaningful)\n",
    "    tagline = clean_text(movie.get('tagline', ''))\n",
    "    if tagline and len(tagline) > 10:\n",
    "        parts.append(f\"Tagline: {tagline}\")\n",
    "    \n",
    "    # Directors\n",
    "    if directors:\n",
    "        director_names = [d['name'] for d in directors if d.get('name')]\n",
    "        if director_names:\n",
    "            parts.append(f\"Directed by: {', '.join(director_names)}\")\n",
    "    \n",
    "    # Top cast\n",
    "    if cast:\n",
    "        cast_names = [c['name'] for c in cast[:5] if c.get('name')]\n",
    "        if cast_names:\n",
    "            parts.append(f\"Starring: {', '.join(cast_names)}\")\n",
    "    \n",
    "    # Keywords (cleaned, top 10)\n",
    "    if keywords:\n",
    "        keyword_names = [k for k in keywords[:10] if k]\n",
    "        if keyword_names:\n",
    "            parts.append(f\"Keywords: {', '.join(keyword_names)}\")\n",
    "    \n",
    "    # Join all parts\n",
    "    return \". \".join(parts)\n",
    "\n",
    "# ==========================================\n",
    "# 4. PROCESSING FUNCTIONS (ENHANCED)\n",
    "# ==========================================\n",
    "\n",
    "def load_processed_ids():\n",
    "    \"\"\"Load list of already processed movie IDs\"\"\"\n",
    "    if os.path.exists(PROCESSED_FILE):\n",
    "        with open(PROCESSED_FILE, 'r') as f:\n",
    "            return set(int(line.strip()) for line in f if line.strip())\n",
    "    return set()\n",
    "\n",
    "def save_processed_id(movie_id):\n",
    "    \"\"\"Save processed movie ID to log file\"\"\"\n",
    "    with open(PROCESSED_FILE, 'a') as f:\n",
    "        f.write(f\"{movie_id}\\n\")\n",
    "\n",
    "def fetch_movie_details(movie_id):\n",
    "    \"\"\"Fetch detailed movie info including credits, keywords, similar movies, etc.\"\"\"\n",
    "    try:\n",
    "        # Movie details\n",
    "        url = f\"{BASE_URL}/movie/{movie_id}\"\n",
    "        params = {'api_key': TMDB_API_KEY, 'language': 'en-US'}\n",
    "        response = requests.get(url, params=params, timeout=10)\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            return None\n",
    "            \n",
    "        movie_data = response.json()\n",
    "        \n",
    "        # Credits (cast & crew)\n",
    "        credits_url = f\"{BASE_URL}/movie/{movie_id}/credits\"\n",
    "        credits_response = requests.get(credits_url, params={'api_key': TMDB_API_KEY}, timeout=10)\n",
    "        \n",
    "        credits_data = {}\n",
    "        if credits_response.status_code == 200:\n",
    "            credits_data = credits_response.json()\n",
    "        \n",
    "        # Keywords\n",
    "        keywords_url = f\"{BASE_URL}/movie/{movie_id}/keywords\"\n",
    "        keywords_response = requests.get(keywords_url, params={'api_key': TMDB_API_KEY}, timeout=10)\n",
    "        \n",
    "        keywords_data = {}\n",
    "        if keywords_response.status_code == 200:\n",
    "            keywords_data = keywords_response.json()\n",
    "        \n",
    "        # Similar movies (recommendations)\n",
    "        similar_url = f\"{BASE_URL}/movie/{movie_id}/similar\"\n",
    "        similar_response = requests.get(similar_url, params={'api_key': TMDB_API_KEY, 'page': 1}, timeout=10)\n",
    "        \n",
    "        similar_data = {}\n",
    "        if similar_response.status_code == 200:\n",
    "            similar_data = similar_response.json()\n",
    "        \n",
    "        return {\n",
    "            'movie': movie_data,\n",
    "            'credits': credits_data,\n",
    "            'keywords': keywords_data,\n",
    "            'similar': similar_data\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ö†Ô∏è Error fetching details for movie {movie_id}: {e}\")\n",
    "        return None\n",
    "\n",
    "def discover_movies(strategy):\n",
    "    \"\"\"Discover movies using a specific strategy\"\"\"\n",
    "    movies = []\n",
    "    seen_ids = set()\n",
    "    \n",
    "    for page in range(1, strategy['pages'] + 1):\n",
    "        try:\n",
    "            params = {\n",
    "                'api_key': TMDB_API_KEY,\n",
    "                'language': 'en-US',\n",
    "                'page': page,\n",
    "                **strategy['params']\n",
    "            }\n",
    "            \n",
    "            response = requests.get(f\"{BASE_URL}/discover/movie\", params=params, timeout=10)\n",
    "            \n",
    "            if response.status_code != 200:\n",
    "                print(f\"   ‚ö†Ô∏è Page {page} failed (status {response.status_code})\")\n",
    "                continue\n",
    "            \n",
    "            data = response.json()\n",
    "            results = data.get('results', [])\n",
    "            \n",
    "            for movie in results:\n",
    "                movie_id = movie.get('id')\n",
    "                \n",
    "                # Skip if already seen or processed\n",
    "                if movie_id in seen_ids:\n",
    "                    continue\n",
    "                    \n",
    "                # Quality filters\n",
    "                vote_count = movie.get('vote_count', 0)\n",
    "                vote_avg = movie.get('vote_average', 0)\n",
    "                overview = movie.get('overview', '')\n",
    "                \n",
    "                if (vote_count >= MIN_VOTE_COUNT and \n",
    "                    vote_avg >= MIN_RATING and \n",
    "                    len(overview) >= MIN_OVERVIEW_LENGTH):\n",
    "                    \n",
    "                    movies.append(movie)\n",
    "                    seen_ids.add(movie_id)\n",
    "            \n",
    "            # Rate limiting\n",
    "            time.sleep(0.25)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ö†Ô∏è Error on page {page}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return movies\n",
    "\n",
    "def save_movie_to_local(movie_id, movie_data):\n",
    "    \"\"\"Save movie data to local JSON file\"\"\"\n",
    "    if not SAVE_LOCAL_DATA:\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        import json\n",
    "        \n",
    "        # Save full movie data\n",
    "        file_path = f\"{LOCAL_DATA_DIR}/movies/{movie_id}.json\"\n",
    "        with open(file_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(movie_data, f, ensure_ascii=False, indent=2)\n",
    "        \n",
    "        # Save poster URL reference\n",
    "        poster_path = movie_data.get('movie', {}).get('poster_path')\n",
    "        if poster_path:\n",
    "            poster_url = f\"{POSTER_BASE_URL}{poster_path}\"\n",
    "            poster_file = f\"{LOCAL_DATA_DIR}/posters/{movie_id}.txt\"\n",
    "            with open(poster_file, 'w') as f:\n",
    "                f.write(poster_url)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ö†Ô∏è Error saving local data for {movie_id}: {e}\")\n",
    "\n",
    "def process_movie(movie_basic):\n",
    "    \"\"\"Process a single movie: fetch details, create embeddings, upload with enhanced graph\"\"\"\n",
    "    movie_id = movie_basic.get('id')\n",
    "    \n",
    "    try:\n",
    "        # Fetch detailed info\n",
    "        details = fetch_movie_details(movie_id)\n",
    "        if not details:\n",
    "            return False\n",
    "        \n",
    "        # ===== VALIDATE DATA QUALITY =====\n",
    "        is_valid, reason = validate_movie_data(details)\n",
    "        if not is_valid:\n",
    "            print(f\"   ‚ö†Ô∏è Skipped {movie_id}: {reason}\")\n",
    "            return False\n",
    "        \n",
    "        movie = details['movie']\n",
    "        credits = details.get('credits', {})\n",
    "        keywords_data = details.get('keywords', {})\n",
    "        similar_data = details.get('similar', {})\n",
    "        \n",
    "        # üÜï SAVE TO LOCAL FIRST (for UI/UX work)\n",
    "        if SAVE_LOCAL_DATA:\n",
    "            save_movie_to_local(movie_id, details)\n",
    "        \n",
    "        # ===== EXTRACT & CLEAN BASIC INFO =====\n",
    "        title = normalize_title(movie.get('title', ''))\n",
    "        if not title:\n",
    "            return False\n",
    "        \n",
    "        overview = clean_text(movie.get('overview', ''))\n",
    "        if not overview or len(overview) < 20:\n",
    "            return False\n",
    "        \n",
    "        genres = deduplicate_list([clean_text(g['name']) for g in movie.get('genres', []) if g.get('name')])\n",
    "        year = movie.get('release_date', '')[:4] if movie.get('release_date') else 'N/A'\n",
    "        rating = float(movie.get('vote_average', 0))\n",
    "        runtime = int(movie.get('runtime', 0)) if movie.get('runtime') else 0\n",
    "        budget = int(movie.get('budget', 0)) if movie.get('budget') else 0\n",
    "        revenue = int(movie.get('revenue', 0)) if movie.get('revenue') else 0\n",
    "        tagline = clean_text(movie.get('tagline', ''))\n",
    "        poster_path = movie.get('poster_path', '')\n",
    "        backdrop_path = movie.get('backdrop_path', '')\n",
    "        \n",
    "        # ===== EXTRACT & CLEAN PRODUCTION INFO =====\n",
    "        production_companies = deduplicate_list(\n",
    "            [clean_text(c['name']) for c in movie.get('production_companies', [])[:3] if c.get('name')]\n",
    "        )\n",
    "        production_countries = deduplicate_list(\n",
    "            [clean_text(c['name']) for c in movie.get('production_countries', []) if c.get('name')]\n",
    "        )\n",
    "        spoken_languages = [clean_text(l['english_name']) for l in movie.get('spoken_languages', []) if l.get('english_name')]\n",
    "        \n",
    "        # Collection info (e.g., Marvel Cinematic Universe)\n",
    "        collection = None\n",
    "        collection_id = None\n",
    "        if movie.get('belongs_to_collection'):\n",
    "            collection = clean_text(movie['belongs_to_collection'].get('name'))\n",
    "            collection_id = movie['belongs_to_collection'].get('id')\n",
    "            if collection and not validate_tmdb_id(collection_id):\n",
    "                collection = None\n",
    "                collection_id = None\n",
    "        \n",
    "        # ===== EXTRACT & CLEAN CREW INFO =====\n",
    "        crew = credits.get('crew', [])\n",
    "        \n",
    "        # Directors (normalized names, validated IDs)\n",
    "        directors = [\n",
    "            {'name': normalize_person_name(c['name']), 'id': c.get('id')} \n",
    "            for c in crew \n",
    "            if c.get('job') == 'Director' and c.get('name') and validate_tmdb_id(c.get('id'))\n",
    "        ]\n",
    "        directors = deduplicate_list(directors, key='id')\n",
    "        \n",
    "        # Writers (normalized, deduplicated)\n",
    "        writers = [\n",
    "            {'name': normalize_person_name(c['name']), 'id': c.get('id')} \n",
    "            for c in crew \n",
    "            if c.get('job') in ['Screenplay', 'Writer', 'Story'] and c.get('name') and validate_tmdb_id(c.get('id'))\n",
    "        ][:3]\n",
    "        writers = deduplicate_list(writers, key='id')\n",
    "        \n",
    "        # Cinematographers\n",
    "        cinematographers = [\n",
    "            {'name': normalize_person_name(c['name']), 'id': c.get('id')} \n",
    "            for c in crew \n",
    "            if c.get('job') == 'Director of Photography' and c.get('name') and validate_tmdb_id(c.get('id'))\n",
    "        ][:1]\n",
    "        \n",
    "        # Composers\n",
    "        composers = [\n",
    "            {'name': normalize_person_name(c['name']), 'id': c.get('id')} \n",
    "            for c in crew \n",
    "            if c.get('job') == 'Original Music Composer' and c.get('name') and validate_tmdb_id(c.get('id'))\n",
    "        ][:2]\n",
    "        composers = deduplicate_list(composers, key='id')\n",
    "        \n",
    "        # Producers\n",
    "        producers = [\n",
    "            {'name': normalize_person_name(c['name']), 'id': c.get('id')} \n",
    "            for c in crew \n",
    "            if c.get('job') in ['Producer', 'Executive Producer'] and c.get('name') and validate_tmdb_id(c.get('id'))\n",
    "        ][:3]\n",
    "        producers = deduplicate_list(producers, key='id')\n",
    "        \n",
    "        # ===== EXTRACT & CLEAN CAST INFO =====\n",
    "        cast_list = credits.get('cast', [])\n",
    "        cast_detailed = [\n",
    "            {\n",
    "                'name': normalize_person_name(c['name']),\n",
    "                'id': c.get('id'),\n",
    "                'character': clean_text(c.get('character', '')),\n",
    "                'order': c.get('order', 999)\n",
    "            }\n",
    "            for c in cast_list[:10]\n",
    "            if c.get('name') and validate_tmdb_id(c.get('id'))\n",
    "        ]\n",
    "        cast_detailed = deduplicate_list(cast_detailed, key='id')\n",
    "        \n",
    "        # ===== EXTRACT & CLEAN KEYWORDS =====\n",
    "        raw_keywords = [clean_keyword(k['name']) for k in keywords_data.get('keywords', []) if k.get('name')]\n",
    "        keywords = deduplicate_list([k for k in raw_keywords if k], key=None)[:15]\n",
    "        \n",
    "        # ===== EXTRACT SIMILAR MOVIES =====\n",
    "        similar_movies = [\n",
    "            {\n",
    "                'id': s['id'],\n",
    "                'title': normalize_title(s.get('title', '')),\n",
    "                'similarity_score': float(s.get('vote_average', 0))\n",
    "            }\n",
    "            for s in similar_data.get('results', [])[:5]\n",
    "            if validate_tmdb_id(s.get('id')) and s.get('title') and s.get('vote_count', 0) > 50\n",
    "        ]\n",
    "        similar_movies = deduplicate_list(similar_movies, key='id')\n",
    "        \n",
    "        # ===== CREATE OPTIMIZED EMBEDDING TEXT =====\n",
    "        text_for_embedding = create_optimized_embedding_text(movie, cast_detailed, keywords, directors)\n",
    "        \n",
    "        # ===== CREATE EMBEDDING =====\n",
    "        embedding = get_gemini_embedding(text_for_embedding, timeout=EMBEDDING_TIMEOUT)\n",
    "        if embedding is None:\n",
    "            return False\n",
    "        \n",
    "        # Rate limiting\n",
    "        time.sleep(0.1 + random.uniform(0, 0.1))\n",
    "        \n",
    "        # ===== UPLOAD TO QDRANT (ENHANCED PAYLOAD) =====\n",
    "        if q_client:\n",
    "            point = PointStruct(\n",
    "                id=movie_id,\n",
    "                vector=embedding,\n",
    "                payload={\n",
    "                    'tmdb_id': movie_id,\n",
    "                    'title': title,\n",
    "                    'overview': overview,\n",
    "                    'genres': genres,\n",
    "                    'year': year,\n",
    "                    'rating': rating,\n",
    "                    'runtime': runtime,\n",
    "                    'tagline': tagline,\n",
    "                    'directors': [d['name'] for d in directors],\n",
    "                    'cast': [c['name'] for c in cast_detailed[:5]],\n",
    "                    'keywords': keywords[:10],\n",
    "                    'companies': production_companies,\n",
    "                    'countries': production_countries,\n",
    "                    'collection': collection,\n",
    "                    'poster_url': f\"{POSTER_BASE_URL}{poster_path}\" if poster_path else None,\n",
    "                    'backdrop_url': f\"{POSTER_BASE_URL}{backdrop_path}\" if backdrop_path else None\n",
    "                }\n",
    "            )\n",
    "            q_client.upsert(collection_name=COLLECTION_NAME, points=[point])\n",
    "        \n",
    "        # ===== UPLOAD TO NEO4J (ENHANCED GRAPH WITH RICH CONNECTIONS) =====\n",
    "        if n_driver:\n",
    "            with n_driver.session() as session:\n",
    "                # Main movie node with all properties\n",
    "                session.run(\"\"\"\n",
    "                    MERGE (m:Movie {id: $id})\n",
    "                    SET m.title = $title,\n",
    "                        m.overview = $overview,\n",
    "                        m.year = $year,\n",
    "                        m.rating = $rating,\n",
    "                        m.runtime = $runtime,\n",
    "                        m.budget = $budget,\n",
    "                        m.revenue = $revenue,\n",
    "                        m.tagline = $tagline,\n",
    "                        m.poster_url = $poster_url,\n",
    "                        m.backdrop_url = $backdrop_url\n",
    "                \"\"\", id=movie_id, title=title, overview=overview, year=year, \n",
    "                     rating=rating, runtime=runtime, budget=budget, revenue=revenue, \n",
    "                     tagline=tagline,\n",
    "                     poster_url=f\"{POSTER_BASE_URL}{poster_path}\" if poster_path else None,\n",
    "                     backdrop_url=f\"{POSTER_BASE_URL}{backdrop_path}\" if backdrop_path else None)\n",
    "                \n",
    "                # Genres\n",
    "                if genres:\n",
    "                    session.run(\"\"\"\n",
    "                        MATCH (m:Movie {id: $id})\n",
    "                        UNWIND $genres as genre_name\n",
    "                        MERGE (g:Genre {name: genre_name})\n",
    "                        MERGE (m)-[:BELONGS_TO]->(g)\n",
    "                    \"\"\", id=movie_id, genres=genres)\n",
    "                \n",
    "                # Directors with DIRECTED_BY relationship\n",
    "                if directors:\n",
    "                    session.run(\"\"\"\n",
    "                        MATCH (m:Movie {id: $id})\n",
    "                        UNWIND $directors as director\n",
    "                        MERGE (p:Person {id: director.id})\n",
    "                        ON CREATE SET p.name = director.name\n",
    "                        MERGE (p)-[:DIRECTED]->(m)\n",
    "                    \"\"\", id=movie_id, directors=directors)\n",
    "                \n",
    "                # Cast with ACTED_IN relationship (with character info)\n",
    "                if cast_detailed:\n",
    "                    session.run(\"\"\"\n",
    "                        MATCH (m:Movie {id: $id})\n",
    "                        UNWIND $cast as actor\n",
    "                        MERGE (p:Person {id: actor.id})\n",
    "                        ON CREATE SET p.name = actor.name\n",
    "                        MERGE (p)-[r:ACTED_IN]->(m)\n",
    "                        SET r.character = actor.character,\n",
    "                            r.order = actor.order\n",
    "                    \"\"\", id=movie_id, cast=cast_detailed)\n",
    "                \n",
    "                # Writers\n",
    "                if writers:\n",
    "                    session.run(\"\"\"\n",
    "                        MATCH (m:Movie {id: $id})\n",
    "                        UNWIND $writers as writer\n",
    "                        MERGE (p:Person {id: writer.id})\n",
    "                        ON CREATE SET p.name = writer.name\n",
    "                        MERGE (p)-[:WROTE]->(m)\n",
    "                    \"\"\", id=movie_id, writers=writers)\n",
    "                \n",
    "                # Cinematographers\n",
    "                if cinematographers:\n",
    "                    session.run(\"\"\"\n",
    "                        MATCH (m:Movie {id: $id})\n",
    "                        UNWIND $cinematographers as cinematographer\n",
    "                        MERGE (p:Person {id: cinematographer.id})\n",
    "                        ON CREATE SET p.name = cinematographer.name\n",
    "                        MERGE (p)-[:CINEMATOGRAPHY]->(m)\n",
    "                    \"\"\", id=movie_id, cinematographers=cinematographers)\n",
    "                \n",
    "                # Composers\n",
    "                if composers:\n",
    "                    session.run(\"\"\"\n",
    "                        MATCH (m:Movie {id: $id})\n",
    "                        UNWIND $composers as composer\n",
    "                        MERGE (p:Person {id: composer.id})\n",
    "                        ON CREATE SET p.name = composer.name\n",
    "                        MERGE (p)-[:COMPOSED_MUSIC]->(m)\n",
    "                    \"\"\", id=movie_id, composers=composers)\n",
    "                \n",
    "                # Production Companies\n",
    "                if production_companies:\n",
    "                    session.run(\"\"\"\n",
    "                        MATCH (m:Movie {id: $id})\n",
    "                        UNWIND $companies as company_name\n",
    "                        MERGE (c:Company {name: company_name})\n",
    "                        MERGE (c)-[:PRODUCED]->(m)\n",
    "                    \"\"\", id=movie_id, companies=production_companies)\n",
    "                \n",
    "                # Countries\n",
    "                if production_countries:\n",
    "                    session.run(\"\"\"\n",
    "                        MATCH (m:Movie {id: $id})\n",
    "                        UNWIND $countries as country_name\n",
    "                        MERGE (c:Country {name: country_name})\n",
    "                        MERGE (m)-[:FILMED_IN]->(c)\n",
    "                    \"\"\", id=movie_id, countries=production_countries)\n",
    "                \n",
    "                # Collection (Movie Series)\n",
    "                if collection and collection_id:\n",
    "                    session.run(\"\"\"\n",
    "                        MATCH (m:Movie {id: $id})\n",
    "                        MERGE (col:Collection {id: $collection_id})\n",
    "                        ON CREATE SET col.name = $collection\n",
    "                        MERGE (m)-[:IN_COLLECTION]->(col)\n",
    "                    \"\"\", id=movie_id, collection_id=collection_id, collection=collection)\n",
    "                \n",
    "                # Keywords\n",
    "                if keywords:\n",
    "                    session.run(\"\"\"\n",
    "                        MATCH (m:Movie {id: $id})\n",
    "                        UNWIND $keywords as keyword_name\n",
    "                        MERGE (k:Keyword {name: keyword_name})\n",
    "                        MERGE (m)-[:HAS_KEYWORD]->(k)\n",
    "                    \"\"\", id=movie_id, keywords=keywords)\n",
    "                \n",
    "                # Similar Movies (recommendations)\n",
    "                if similar_movies:\n",
    "                    session.run(\"\"\"\n",
    "                        MATCH (m:Movie {id: $id})\n",
    "                        UNWIND $similar as sim\n",
    "                        MERGE (other:Movie {id: sim.id})\n",
    "                        ON CREATE SET other.title = sim.title\n",
    "                        MERGE (m)-[r:SIMILAR_TO]->(other)\n",
    "                        SET r.score = sim.similarity_score\n",
    "                    \"\"\", id=movie_id, similar=similar_movies)\n",
    "                \n",
    "                # Create WORKED_WITH relationships (people who collaborated)\n",
    "                # Directors <-> Actors\n",
    "                if directors and cast_detailed:\n",
    "                    session.run(\"\"\"\n",
    "                        MATCH (m:Movie {id: $id})\n",
    "                        MATCH (d:Person)-[:DIRECTED]->(m)<-[:ACTED_IN]-(a:Person)\n",
    "                        MERGE (d)-[r:WORKED_WITH]-(a)\n",
    "                        ON CREATE SET r.count = 1, r.movies = [m.title]\n",
    "                        ON MATCH SET r.count = r.count + 1, \n",
    "                                     r.movies = r.movies + [m.title]\n",
    "                    \"\"\", id=movie_id)\n",
    "                \n",
    "                # Co-stars (actors who worked together)\n",
    "                if len(cast_detailed) >= 2:\n",
    "                    session.run(\"\"\"\n",
    "                        MATCH (m:Movie {id: $id})\n",
    "                        MATCH (a1:Person)-[:ACTED_IN]->(m)<-[:ACTED_IN]-(a2:Person)\n",
    "                        WHERE a1.id < a2.id\n",
    "                        MERGE (a1)-[r:CO_STARRED]-(a2)\n",
    "                        ON CREATE SET r.count = 1, r.movies = [m.title]\n",
    "                        ON MATCH SET r.count = r.count + 1,\n",
    "                                     r.movies = r.movies + [m.title]\n",
    "                    \"\"\", id=movie_id)\n",
    "        \n",
    "        save_processed_id(movie_id)\n",
    "        print(f\"   ‚úÖ {title} ({len(cast_detailed)} cast, {len(keywords)} kw, {len(similar_movies)} sim)\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Error processing {movie_id}: {str(e)[:150]}\")\n",
    "        return False\n",
    "\n",
    "# ==========================================\n",
    "# 4. MAIN PIPELINE\n",
    "# ==========================================\n",
    "\n",
    "processed_ids = load_processed_ids()\n",
    "print(f\"üìã Already processed: {len(processed_ids)} movies\\n\")\n",
    "        \n",
    "total_discovered = 0\n",
    "total_processed = 0\n",
    "total_failed = 0\n",
    "# ==========================================\n",
    "for strategy in DISCOVERY_STRATEGIES:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"üéØ STRATEGY: {strategy['name']}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Discover movies\n",
    "    print(f\"üîç Discovering movies...\")\n",
    "    movies = discover_movies(strategy)\n",
    "    print(f\"‚úÖ Found {len(movies)} candidate movies\\n\")\n",
    "    \n",
    "    # Filter already processed\n",
    "    new_movies = [m for m in movies if m['id'] not in processed_ids]\n",
    "    print(f\"üì• New movies to process: {len(new_movies)}\\n\")\n",
    "    \n",
    "    total_discovered += len(movies)\n",
    "    \n",
    "    # Process in batches\n",
    "    for i in range(0, len(new_movies), BATCH_SIZE):\n",
    "        batch = new_movies[i:i+BATCH_SIZE]\n",
    "        batch_num = (i // BATCH_SIZE) + 1\n",
    "        print(f\"\\nüîÑ Batch {batch_num}/{(len(new_movies) + BATCH_SIZE - 1) // BATCH_SIZE}...\")\n",
    "        \n",
    "        batch_success = 0\n",
    "        for movie in batch:\n",
    "            success = process_movie(movie)\n",
    "            if success:\n",
    "                batch_success += 1\n",
    "                total_processed += 1\n",
    "            else:\n",
    "                total_failed += 1\n",
    "        \n",
    "        print(f\"   üìä Batch result: {batch_success}/{len(batch)} successful\")\n",
    "        \n",
    "        # Rate limiting between batches (‚ö° MINIMAL)\n",
    "        time.sleep(0.5)  # ‚ö° Gi·∫£m t·ª´ 1.5s -> 0.5s\n",
    "\n",
    "# ==========================================\n",
    "# 5. SUMMARY\n",
    "# ==========================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéâ CRAWL COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nüìä Statistics:\")\n",
    "print(f\"   ‚Ä¢ Total discovered: {total_discovered}\")\n",
    "print(f\"   ‚Ä¢ Successfully processed: {total_processed}\")\n",
    "print(f\"   ‚Ä¢ Failed: {total_failed}\")\n",
    "print(f\"   ‚Ä¢ Success rate: {total_processed / max(total_discovered, 1) * 100:.1f}%\")\n",
    "\n",
    "if SAVE_LOCAL_DATA:\n",
    "    print(f\"\\nüìÅ Local Data Saved:\")\n",
    "    print(f\"   ‚Ä¢ Location: {LOCAL_DATA_DIR}/\")\n",
    "    print(f\"   ‚Ä¢ Movies JSON: {LOCAL_DATA_DIR}/movies/\")\n",
    "    print(f\"   ‚Ä¢ Poster URLs: {LOCAL_DATA_DIR}/posters/\")\n",
    "    \n",
    "    # Create index file\n",
    "    try:\n",
    "        import json\n",
    "        import os\n",
    "        \n",
    "        movie_files = os.listdir(f\"{LOCAL_DATA_DIR}/movies\")\n",
    "        movie_index = []\n",
    "        \n",
    "        for file in movie_files:\n",
    "            if file.endswith('.json'):\n",
    "                try:\n",
    "                    with open(f\"{LOCAL_DATA_DIR}/movies/{file}\", 'r', encoding='utf-8') as f:\n",
    "                        data = json.load(f)\n",
    "                        movie = data.get('movie', {})\n",
    "                        poster_path = movie.get('poster_path', '')\n",
    "                        \n",
    "                        movie_index.append({\n",
    "                            'id': movie.get('id'),\n",
    "                            'title': movie.get('title'),\n",
    "                            'year': movie.get('release_date', '')[:4] if movie.get('release_date') else 'N/A',\n",
    "                            'rating': movie.get('vote_average', 0),\n",
    "                            'genres': [g['name'] for g in movie.get('genres', [])],\n",
    "                            'poster_url': f\"{POSTER_BASE_URL}{poster_path}\" if poster_path else None,\n",
    "                            'file': file\n",
    "                        })\n",
    "                except:\n",
    "                    pass\n",
    "        \n",
    "        # Sort by rating\n",
    "        movie_index.sort(key=lambda x: x['rating'], reverse=True)\n",
    "        \n",
    "        # Save index\n",
    "        index_file = f\"{LOCAL_DATA_DIR}/movies_index.json\"\n",
    "        with open(index_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump({\n",
    "                'total_movies': len(movie_index),\n",
    "                'crawl_date': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                'movies': movie_index\n",
    "            }, f, ensure_ascii=False, indent=2)\n",
    "        \n",
    "        print(f\"\\n‚úÖ Created index file: {index_file}\")\n",
    "        print(f\"   ‚Ä¢ Contains {len(movie_index)} movies\")\n",
    "        print(f\"   ‚Ä¢ Sorted by rating (highest first)\")\n",
    "        print(f\"\\nüí° Use this index for UI/UX development!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ö†Ô∏è  Could not create index: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "542dbfc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üß™ TESTING GEMINI EMBEDDING API\n",
      "======================================================================\n",
      "\n",
      "1Ô∏è‚É£ Test 1: Simple embedding call (no timeout)...\n",
      "   ‚ùå Failed: 404 models/text-embedding-001 is not found for API version v1beta, or is not supported for embedContent. Call ListModels to see the list of available models and their supported methods.\n",
      "\n",
      "2Ô∏è‚É£ Test 2: Embedding with 10s timeout...\n",
      "   ‚úÖ Success! Got 768 dimensions in 312ms\n",
      "   ‚è±Ô∏è  Timeout mechanism working (didn't trigger)\n",
      "\n",
      "3Ô∏è‚É£ Test 3: English text embedding...\n",
      "   ‚úÖ Success! English text embedded in 224ms\n",
      "   üìä Embedding size: 768 dims\n",
      "\n",
      "4Ô∏è‚É£ Test 4: Available embedding models...\n",
      "   ‚úÖ Found 6 embedding model(s):\n",
      "      ‚Ä¢ models/embedding-gecko-001\n",
      "      ‚Ä¢ models/embedding-001\n",
      "      ‚Ä¢ models/text-embedding-004\n",
      "      ‚Ä¢ models/gemini-embedding-exp-03-07\n",
      "      ‚Ä¢ models/gemini-embedding-exp\n",
      "\n",
      "======================================================================\n",
      "‚úÖ TEST COMPLETE\n",
      "======================================================================\n",
      "\n",
      "üí° Summary:\n",
      "   ‚Ä¢ If Test 1-3 passed ‚Üí API working well\n",
      "   ‚Ä¢ If timeout in Test 2 ‚Üí Network/API too slow\n",
      "   ‚Ä¢ If all failed ‚Üí Check API key or quota\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# üß™ TEST: Gemini Embedding API\n",
    "print(\"=\" * 70)\n",
    "print(\"üß™ TESTING GEMINI EMBEDDING API\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "import time\n",
    "import signal\n",
    "\n",
    "# Configure\n",
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\", \"AIzaSyDb3B5gPGV8pGgHFBmwEC4XwfzmBgnJCW0\"))\n",
    "\n",
    "# Test 1: Simple call WITHOUT timeout\n",
    "print(\"\\n1Ô∏è‚É£ Test 1: Simple embedding call (no timeout)...\")\n",
    "try:\n",
    "    start = time.time()\n",
    "    result = genai.embed_content(\n",
    "        model=\"models/text-embedding-001\",\n",
    "        content=\"This is a test sentence\",\n",
    "        task_type=\"retrieval_document\"\n",
    "    )\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    embedding = result['embedding']\n",
    "    print(f\"   ‚úÖ Success! Got {len(embedding)} dimensions in {elapsed*1000:.0f}ms\")\n",
    "    print(f\"   üìä First 5 values: {embedding[:5]}\")\n",
    "except Exception as e:\n",
    "    print(f\"   ‚ùå Failed: {str(e)[:200]}\")\n",
    "\n",
    "# Test 2: Call WITH timeout (signal-based)\n",
    "print(\"\\n2Ô∏è‚É£ Test 2: Embedding with 10s timeout...\")\n",
    "\n",
    "def timeout_handler(signum, frame):\n",
    "    raise TimeoutError(\"API call exceeded timeout\")\n",
    "\n",
    "try:\n",
    "    start = time.time()\n",
    "    \n",
    "    # Set 10s timeout\n",
    "    signal.signal(signal.SIGALRM, timeout_handler)\n",
    "    signal.alarm(10)\n",
    "    \n",
    "    try:\n",
    "        result = genai.embed_content(\n",
    "            model=\"models/text-embedding-004\",\n",
    "            content=\"Test with timeout protection\",\n",
    "            task_type=\"retrieval_document\"\n",
    "        )\n",
    "        signal.alarm(0)  # Cancel timeout\n",
    "        \n",
    "        elapsed = time.time() - start\n",
    "        embedding = result['embedding']\n",
    "        print(f\"   ‚úÖ Success! Got {len(embedding)} dimensions in {elapsed*1000:.0f}ms\")\n",
    "        print(f\"   ‚è±Ô∏è  Timeout mechanism working (didn't trigger)\")\n",
    "        \n",
    "    finally:\n",
    "        signal.alarm(0)\n",
    "        \n",
    "except TimeoutError:\n",
    "    print(f\"   ‚è±Ô∏è  Timeout triggered after 10s\")\n",
    "except Exception as e:\n",
    "    print(f\"   ‚ùå Failed: {str(e)[:200]}\")\n",
    "\n",
    "# Test 3: English text embedding\n",
    "print(\"\\n3Ô∏è‚É£ Test 3: English text embedding...\")\n",
    "try:\n",
    "    start = time.time()\n",
    "    result = genai.embed_content(\n",
    "        model=\"models/text-embedding-004\",\n",
    "        content=\"This is an exciting action movie about superheroes\",\n",
    "        task_type=\"retrieval_document\"\n",
    "    )\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    embedding = result['embedding']\n",
    "    print(f\"   ‚úÖ Success! English text embedded in {elapsed*1000:.0f}ms\")\n",
    "    print(f\"   üìä Embedding size: {len(embedding)} dims\")\n",
    "except Exception as e:\n",
    "    print(f\"   ‚ùå Failed: {str(e)[:200]}\")\n",
    "\n",
    "# Test 4: Check model versions available\n",
    "print(\"\\n4Ô∏è‚É£ Test 4: Available embedding models...\")\n",
    "try:\n",
    "    models = genai.list_models()\n",
    "    embedding_models = [m for m in models if 'embedding' in m.name.lower()]\n",
    "    \n",
    "    if embedding_models:\n",
    "        print(f\"   ‚úÖ Found {len(embedding_models)} embedding model(s):\")\n",
    "        for model in embedding_models[:5]:  # Show first 5\n",
    "            print(f\"      ‚Ä¢ {model.name}\")\n",
    "    else:\n",
    "        print(\"   ‚ö†Ô∏è  No embedding models found (this might be a display issue)\")\n",
    "except Exception as e:\n",
    "    print(f\"   ‚ö†Ô∏è  Could not list models: {str(e)[:100]}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚úÖ TEST COMPLETE\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nüí° Summary:\")\n",
    "print(\"   ‚Ä¢ If Test 1-3 passed ‚Üí API working well\")\n",
    "print(\"   ‚Ä¢ If timeout in Test 2 ‚Üí Network/API too slow\")\n",
    "print(\"   ‚Ä¢ If all failed ‚Üí Check API key or quota\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bbf6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üé¨ VECTOR SEARCH TEST - Choose a query type:\n",
      "======================================================================\n",
      "1. H√†nh ƒë·ªông: Phim h√†nh ƒë·ªông b·∫Øn s√∫ng k·ªãch t√≠nh\n",
      "2. ƒê·∫°o di·ªÖn: Phim c·ªßa Christopher Nolan\n",
      "3. Di·ªÖn vi√™n: Phim c√≥ Tom Hanks ƒë√≥ng\n",
      "4. Th·ªÉ lo·∫°i + NƒÉm: Phim khoa h·ªçc vi·ªÖn t∆∞·ªüng nƒÉm 2010\n",
      "5. Mood: Phim bu·ªìn v·ªÅ t√¨nh y√™u\n",
      "6. Custom: <Enter your own query>\n",
      "\n",
      "======================================================================\n",
      "\n",
      "üîé Searching for: \"Phim h√†nh ƒë·ªông b·∫Øn s√∫ng k·ªãch t√≠nh\"\n",
      "\n",
      "======================================================================\n",
      "üéØ SEARCH RESULTS (5 found)\n",
      "======================================================================\n",
      "‚ö° Embedding time: 435.3ms | Search time: 1222.0ms\n",
      "\n",
      "1. üé¨ Chuy·ªán t√¨nh t√≥c r·ªëi (2025)\n",
      "   ‚úÖ Good Match | Score: 0.623\n",
      "   üìÇ Genres: Phim L√£ng M·∫°n, Phim Ch√≠nh K·ªãch, Phim H√†i\n",
      "   üé• Director: Namkoong Sun\n",
      "   üë• Cast: Shin Eun-soo, Gong Myoung, Cha Woo-min\n",
      "   ‚≠ê‚≠ê‚≠ê‚≠ê 8.39/10\n",
      "   üìù M·ªôt thi·∫øu n·ªØ si t√¨nh l√™n k·∫ø ho·∫°ch chinh ph·ª•c nam th·∫ßn c·ªßa tr∆∞·ªùng b·∫±ng c√°ch chuy·ªÉn t·ª´ t√≥c xoƒÉn sang t√≥c th·∫≥ng ‚Äì cho ƒë·∫øn k...\n",
      "\n",
      "2. üé¨ Cu·ªôc S·ªëng T∆∞∆°i ƒê·∫πp (1997)\n",
      "   ‚úÖ Good Match | Score: 0.622\n",
      "   üìÇ Genres: Phim H√†i, Phim Ch√≠nh K·ªãch\n",
      "   üé• Director: Roberto Benigni\n",
      "   üë• Cast: Roberto Benigni, Nicoletta Braschi, Giorgio Cantarini\n",
      "   ‚≠ê‚≠ê‚≠ê‚≠ê 8.4/10\n",
      "   üìù M·ªôt c√¢u chuy·ªán c·ªï t√≠ch gi·ªØa ƒë·ªùi th∆∞·ªùng ƒë·∫ßy c·∫£m ƒë·ªông v·ªÅ ch√†ng b√°n s√°ch ng∆∞·ªùi √ù g·ªëc Do Th√°i. Cu·ªôc s·ªëng gia ƒë√¨nh h·∫°nh ph√∫c ...\n",
      "\n",
      "3. üé¨ Bƒ© C·ª±c Th√°i Lai (2025)\n",
      "   ‚úÖ Good Match | Score: 0.621\n",
      "   üìÇ Genres: Phim Khoa H·ªçc Vi·ªÖn T∆∞·ªüng, Phim H√¨nh S·ª±\n",
      "   üé• Director: Yorgos Lanthimos\n",
      "   üë• Cast: Emma Stone, Jesse Plemons, Aidan Delbis\n",
      "   ‚≠ê‚≠ê‚≠ê 7.4/10\n",
      "   üìù Hai thanh ni√™n √°m ·∫£nh v·ªõi thuy·∫øt √¢m m∆∞u ƒë√£ b·∫Øt c√≥c n·ªØ CEO quy·ªÅn l·ª±c c·ªßa m·ªôt t·∫≠p ƒëo√†n l·ªõn, tin ch·∫Øc r·∫±ng b√† ta th·ª±c ch·∫•t ...\n",
      "\n",
      "4. üé¨ 12 Ng∆∞·ªùi ƒê√†n √îng Gi·∫≠n D·ªØ (1957)\n",
      "   ‚úÖ Good Match | Score: 0.621\n",
      "   üìÇ Genres: Phim Ch√≠nh K·ªãch\n",
      "   üé• Director: Sidney Lumet\n",
      "   üë• Cast: Martin Balsam, John Fiedler, Lee J. Cobb\n",
      "   ‚≠ê‚≠ê‚≠ê‚≠ê 8.55/10\n",
      "   üìù M·ªôt thanh ni√™n b·ªã t√¨nh nghi gi·∫øt cha ru·ªôt c·ªßa m√¨nh. 12 ng∆∞·ªùi c·ªßa b·ªìi th·∫©m ƒëo√†n b·∫Øt ƒë·∫ßu phi√™n l√†m vi·ªác c·ªßa m√¨nh v√† t·∫•t c·∫£...\n",
      "\n",
      "5. üé¨ V·ªã Kh√°ch B·∫•t Ng·ªù (2025)\n",
      "   ‚úÖ Good Match | Score: 0.620\n",
      "   üìÇ Genres: Phim Ch√≠nh K·ªãch, Phim G√¢y C·∫•n, Phim H√¨nh S·ª±\n",
      "   üé• Director: Jafar Panahi\n",
      "   üë• Cast: Vahid Mobasseri, Mariam Afshari, Ebrahim Azizi\n",
      "   ‚≠ê‚≠ê‚≠ê 7.175/10\n",
      "   üìù M·ªôt c·ª±u t√π nh√¢n ch√≠nh tr·ªã nghi ng·ªù r·∫±ng ng∆∞·ªùi kh√°ch b∆∞·ªõc v√†o x∆∞·ªüng s·ª≠a xe c·ªßa m√¨nh ch√≠nh l√† k·∫ª t·ª´ng tra t·∫•n anh, bu·ªôc an...\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# üîç Test Vector Search with Multiple Query Types\n",
    "import time\n",
    "\n",
    "# Sample queries to test different scenarios\n",
    "test_queries = {\n",
    "    \"1. Action\": \"Action movies with intense gunfights\",\n",
    "    \"2. Director\": \"Movies by Christopher Nolan\",\n",
    "    \"3. Actor\": \"Movies starring Tom Hanks\",\n",
    "    \"4. Genre + Year\": \"Science fiction movies from 2010\",\n",
    "    \"5. Mood\": \"Sad movies about love\",\n",
    "    \"6. Custom\": None  # User's own query\n",
    "}\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"üé¨ VECTOR SEARCH TEST - Choose a query type:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for key, query in test_queries.items():\n",
    "    if query:\n",
    "        print(f\"{key}: {query}\")\n",
    "    else:\n",
    "        print(f\"{key}: <Enter your own query>\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "\n",
    "# You can change this to test different queries\n",
    "query_choice = \"1\"  # Change to \"1\", \"2\", \"3\", \"4\", \"5\", or \"6\"\n",
    "custom_query = \"Best Korean horror movies\"  # Used if query_choice = \"6\"\n",
    "\n",
    "# Get the query\n",
    "if query_choice == \"6\":\n",
    "    query_text = custom_query\n",
    "else:\n",
    "    query_key = f\"{query_choice}. \" + [k.split(\". \")[1] for k in test_queries.keys() if k.startswith(query_choice)][0]\n",
    "    query_text = test_queries[query_key]\n",
    "\n",
    "print(f\"\\nüîé Searching for: \\\"{query_text}\\\"\\n\")\n",
    "\n",
    "try:\n",
    "    # Check if clients exist\n",
    "    if 'q_client' not in locals():\n",
    "        if 'qdrant_client' in locals():\n",
    "            q_client = qdrant_client\n",
    "        else:\n",
    "            print(\"‚ùå Qdrant client not found. Please run Cell 4 first.\")\n",
    "            raise NameError(\"q_client not defined\")\n",
    "    \n",
    "    # OLD: SentenceTransformer (comment out - causes embedding mismatch)\n",
    "    # if 'embed_model' not in locals():\n",
    "    #     print(\"‚è≥ Loading embedding model (first time only)...\")\n",
    "    #     from sentence_transformers import SentenceTransformer\n",
    "    #     embed_model = SentenceTransformer('paraphrase-multilingual-mpnet-base-v2')\n",
    "    #     print(\"‚úÖ Model loaded\\n\")\n",
    "    # query_vector = embed_model.encode(query_text).tolist()\n",
    "    \n",
    "    # NEW: Use Gemini Embedding (matches current system)\n",
    "    if 'gemini_configured' not in locals():\n",
    "        print(\"‚è≥ Configuring Gemini embedding model...\")\n",
    "        import google.generativeai as genai\n",
    "        genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\", \"AIzaSyDb3B5gPGV8pGgHFBmwEC4XwfzmBgnJCW0\"))\n",
    "        gemini_configured = True\n",
    "        print(\"‚úÖ Gemini configured\\n\")\n",
    "    \n",
    "    # Create query vector using Gemini with retry logic\n",
    "    start_time = time.time()\n",
    "    max_retries = 3\n",
    "    query_vector = None\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            result = genai.embed_content(\n",
    "                model=\"models/text-embedding-004\",\n",
    "                content=query_text,\n",
    "                task_type=\"retrieval_query\"\n",
    "            )\n",
    "            query_vector = result['embedding']\n",
    "            break\n",
    "        except Exception as e:\n",
    "            error_msg = str(e).lower()\n",
    "            if \"429\" in error_msg or \"rate\" in error_msg:\n",
    "                wait_time = 5 * (attempt + 1)\n",
    "                print(f\"‚è≥ Rate limited, waiting {wait_time}s...\")\n",
    "                time.sleep(wait_time)\n",
    "            else:\n",
    "                print(f\"‚ùå Error: {str(e)[:150]}\")\n",
    "                break\n",
    "    \n",
    "    if query_vector is None:\n",
    "        print(\"‚ùå Failed to create query vector\")\n",
    "        raise ValueError(\"Embedding failed\")\n",
    "    \n",
    "    embed_time = time.time() - start_time\n",
    "    print(f\"‚úÖ Query embedded in {embed_time*1000:.0f}ms\\n\")\n",
    "    \n",
    "    # Search in Qdrant\n",
    "    print(\"‚è≥ Searching vector database...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    results = q_client.search(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        query_vector=query_vector,\n",
    "        limit=10\n",
    "    )\n",
    "    \n",
    "    search_time = time.time() - start_time\n",
    "    \n",
    "    # Display results\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"üé¨ SEARCH RESULTS (found {len(results)} movies in {search_time*1000:.0f}ms)\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    if results:\n",
    "        for i, hit in enumerate(results, 1):\n",
    "            score = hit.score\n",
    "            payload = hit.payload\n",
    "            \n",
    "            title = payload.get('title', 'Unknown')\n",
    "            year = payload.get('year', 'N/A')\n",
    "            movie_id = payload.get('movie_id', 'N/A')\n",
    "            \n",
    "            # Color-coded relevance\n",
    "            if score >= 0.7:\n",
    "                emoji = \"üü¢\"\n",
    "                relevance = \"High\"\n",
    "            elif score >= 0.5:\n",
    "                emoji = \"üü°\"\n",
    "                relevance = \"Medium\"\n",
    "            else:\n",
    "                emoji = \"üî¥\"\n",
    "                relevance = \"Low\"\n",
    "            \n",
    "            print(f\"\\n{i}. {emoji} {title} ({year})\")\n",
    "            print(f\"   Score: {score:.4f} | Relevance: {relevance}\")\n",
    "            print(f\"   ID: {movie_id}\")\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è No results found. Try a different query.\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error during search: {str(e)[:200]}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57cf8a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üï∏Ô∏è NEO4J GRAPH QUERY TEST\n",
      "======================================================================\n",
      "\n",
      "Available queries:\n",
      "  0. List Available Genres (Diagnostic)\n",
      "  1. Movies by Genre\n",
      "  2. Movies by Director\n",
      "  3. Movies with Actor\n",
      "  4. Genre Co-occurrence\n",
      "  5. Director-Actor Collaborations\n",
      "\n",
      "======================================================================\n",
      "\n",
      "üîç Running: List Available Genres (Diagnostic)\n",
      "\n",
      "======================================================================\n",
      "üìä RESULTS (20 found)\n",
      "======================================================================\n",
      "\n",
      " 1. Phim Ch√≠nh K·ªãch...............  280 movies ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      " 2. Drama.........................  251 movies ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      " 3. Phim H√†nh ƒê·ªông................  223 movies ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      " 4. Action........................  198 movies ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      " 5. Phim Phi√™u L∆∞u................  188 movies ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      " 6. Adventure.....................  181 movies ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      " 7. Phim G√¢y C·∫•n..................  175 movies ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      " 8. Phim H√†i......................  162 movies ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      " 9. Comedy........................  150 movies ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "10. Thriller......................  137 movies ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "11. Fantasy.......................  128 movies ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "12. Phim Gi·∫£ T∆∞·ª£ng................  126 movies ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "13. Phim Ho·∫°t H√¨nh................  116 movies ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "14. Animation.....................  116 movies ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "15. Phim Khoa H·ªçc Vi·ªÖn T∆∞·ªüng......  111 movies ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "16. Science Fiction...............  110 movies ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "17. Phim L√£ng M·∫°n.................  107 movies ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "18. Phim Gia ƒê√¨nh.................  103 movies ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "19. Phim H√¨nh S·ª±..................  103 movies ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "20. Family........................   94 movies ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "======================================================================\n",
      "\n",
      "üí° Tip: Copy genre names above to use in queries 1 and 4\n",
      "   Example: Change query_choice to '1' and set:\n",
      "   \"params\": {\"genre\": \"Phim Ch√≠nh K·ªãch\"}\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# üï∏Ô∏è Test Graph Search trong Neo4j v·ªõi Multiple Patterns\n",
    "\n",
    "# Different graph query patterns to test\n",
    "graph_queries = {\n",
    "    \"0\": {\n",
    "        \"name\": \"List Available Genres (Diagnostic)\",\n",
    "        \"cypher\": \"\"\"\n",
    "            MATCH (g:Genre)<-[:BELONGS_TO]-(m:Movie)\n",
    "            RETURN g.name as genre, count(m) as movie_count\n",
    "            ORDER BY movie_count DESC\n",
    "            LIMIT 20\n",
    "        \"\"\",\n",
    "        \"params\": {}\n",
    "    },\n",
    "    \"1\": {\n",
    "        \"name\": \"Movies by Genre\",\n",
    "        \"cypher\": \"\"\"\n",
    "            MATCH (m:Movie)-[:BELONGS_TO]->(g:Genre {name: $genre})\n",
    "            OPTIONAL MATCH (d:Person)-[:DIRECTED]->(m)\n",
    "            RETURN m.title as title, m.year as year, m.rating as rating, \n",
    "                   d.name as director, labels(m) as labels\n",
    "            ORDER BY m.rating DESC\n",
    "            LIMIT 5\n",
    "        \"\"\",\n",
    "        \"params\": {\"genre\": \"Action\"}  # Try: \"H√†nh ƒê·ªông\", \"Phi√™u L∆∞u\", \"Khoa H·ªçc Vi·ªÖn T∆∞·ªüng\"\n",
    "    },\n",
    "    \"2\": {\n",
    "        \"name\": \"Movies by Director\",\n",
    "        \"cypher\": \"\"\"\n",
    "            MATCH (d:Person {name: $director})-[:DIRECTED]->(m:Movie)\n",
    "            OPTIONAL MATCH (m)-[:BELONGS_TO]->(g:Genre)\n",
    "            RETURN m.title as title, m.year as year, m.rating as rating,\n",
    "                   collect(DISTINCT g.name) as genres\n",
    "            ORDER BY m.year DESC\n",
    "            LIMIT 5\n",
    "        \"\"\",\n",
    "        \"params\": {\"director\": \"Christopher Nolan\"}\n",
    "    },\n",
    "    \"3\": {\n",
    "        \"name\": \"Movies with Actor\",\n",
    "        \"cypher\": \"\"\"\n",
    "            MATCH (p:Person {name: $actor})-[:ACTED_IN]->(m:Movie)\n",
    "            OPTIONAL MATCH (d:Person)-[:DIRECTED]->(m)\n",
    "            OPTIONAL MATCH (m)-[:BELONGS_TO]->(g:Genre)\n",
    "            RETURN m.title as title, m.year as year, d.name as director,\n",
    "                   collect(DISTINCT g.name)[..3] as genres\n",
    "            ORDER BY m.rating DESC\n",
    "            LIMIT 5\n",
    "        \"\"\",\n",
    "        \"params\": {\"actor\": \"Tom Hanks\"}\n",
    "    },\n",
    "    \"4\": {\n",
    "        \"name\": \"Genre Co-occurrence\",\n",
    "        \"cypher\": \"\"\"\n",
    "            MATCH (g1:Genre {name: $genre1})<-[:BELONGS_TO]-(m:Movie)-[:BELONGS_TO]->(g2:Genre)\n",
    "            WHERE g2.name <> $genre1\n",
    "            RETURN g2.name as related_genre, count(m) as count\n",
    "            ORDER BY count DESC\n",
    "            LIMIT 5\n",
    "        \"\"\",\n",
    "        \"params\": {\"genre1\": \"Action\"}\n",
    "    },\n",
    "    \"5\": {\n",
    "        \"name\": \"Director-Actor Collaborations\",\n",
    "        \"cypher\": \"\"\"\n",
    "            MATCH (d:Person)-[:DIRECTED]->(m:Movie)<-[:ACTED_IN]-(a:Person)\n",
    "            WHERE d.name = $director\n",
    "            RETURN a.name as actor, count(m) as collaborations, \n",
    "                   collect(m.title)[..3] as movies\n",
    "            ORDER BY collaborations DESC\n",
    "            LIMIT 5\n",
    "        \"\"\",\n",
    "        \"params\": {\"director\": \"Christopher Nolan\"}\n",
    "    }\n",
    "}\n",
    "\n",
    "# Choose which query to run (change this number: 0-5)\n",
    "# Start with \"0\" to see available genres!\n",
    "query_choice = \"0\"\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"üï∏Ô∏è NEO4J GRAPH QUERY TEST\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nAvailable queries:\")\n",
    "for key, info in graph_queries.items():\n",
    "    print(f\"  {key}. {info['name']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "\n",
    "query_info = graph_queries[query_choice]\n",
    "print(f\"\\nüîç Running: {query_info['name']}\")\n",
    "if query_info['params']:\n",
    "    print(f\"üìä Parameters: {query_info['params']}\")\n",
    "print()\n",
    "\n",
    "try:\n",
    "    # Check if n_driver exists and is usable\n",
    "    driver_needs_reconnect = False\n",
    "    \n",
    "    if 'n_driver' not in locals():\n",
    "        driver_needs_reconnect = True\n",
    "    else:\n",
    "        # Test if existing driver is still open\n",
    "        try:\n",
    "            with n_driver.session() as test_session:\n",
    "                test_session.run(\"RETURN 1\")\n",
    "        except Exception:\n",
    "            driver_needs_reconnect = True\n",
    "            # Close the old driver if it exists\n",
    "            try:\n",
    "                n_driver.close()\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    # Reconnect if needed\n",
    "    if driver_needs_reconnect:\n",
    "        print(\"‚è≥ Connecting to Neo4j...\")\n",
    "        from neo4j import GraphDatabase\n",
    "        n_driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD))\n",
    "        print(\"‚úÖ Connected\\n\")\n",
    "    \n",
    "    # Execute query\n",
    "    with n_driver.session() as session:\n",
    "        result = session.run(query_info['cypher'], query_info['params'])\n",
    "        records = list(result)\n",
    "        \n",
    "        if records:\n",
    "            print(\"=\" * 70)\n",
    "            print(f\"üìä RESULTS ({len(records)} found)\")\n",
    "            print(\"=\" * 70 + \"\\n\")\n",
    "            \n",
    "            for i, record in enumerate(records, 1):\n",
    "                record_dict = dict(record)\n",
    "                \n",
    "                # Display based on query type\n",
    "                if query_choice == \"0\":  # List Genres\n",
    "                    genre_name = record_dict['genre']\n",
    "                    count = record_dict['movie_count']\n",
    "                    bar = \"‚ñà\" * min(int(count / max(1, records[0]['movie_count']) * 30), 30)\n",
    "                    print(f\"{i:2d}. {genre_name:.<30} {count:>4} movies {bar}\")\n",
    "                    \n",
    "                elif query_choice == \"1\":  # Movies by Genre\n",
    "                    print(f\"{i}. üé¨ {record_dict['title']} ({record_dict['year']})\")\n",
    "                    if record_dict.get('director'):\n",
    "                        print(f\"   üé• Director: {record_dict['director']}\")\n",
    "                    if record_dict.get('rating'):\n",
    "                        print(f\"   ‚≠ê Rating: {record_dict['rating']}/10\")\n",
    "                    \n",
    "                elif query_choice == \"2\":  # Movies by Director\n",
    "                    print(f\"{i}. üé¨ {record_dict['title']} ({record_dict['year']})\")\n",
    "                    genres = record_dict.get('genres', [])\n",
    "                    if genres:\n",
    "                        print(f\"   üìÇ Genres: {', '.join(genres)}\")\n",
    "                    if record_dict.get('rating'):\n",
    "                        print(f\"   ‚≠ê Rating: {record_dict['rating']}/10\")\n",
    "                    \n",
    "                elif query_choice == \"3\":  # Movies with Actor\n",
    "                    print(f\"{i}. üé¨ {record_dict['title']} ({record_dict['year']})\")\n",
    "                    if record_dict.get('director'):\n",
    "                        print(f\"   üé• Director: {record_dict['director']}\")\n",
    "                    genres = record_dict.get('genres', [])\n",
    "                    if genres:\n",
    "                        print(f\"   üìÇ Genres: {', '.join(genres)}\")\n",
    "                    \n",
    "                elif query_choice == \"4\":  # Genre Co-occurrence\n",
    "                    print(f\"{i}. üìÇ {record_dict['related_genre']}\")\n",
    "                    print(f\"   üìä Co-occurs in {record_dict['count']} movies\")\n",
    "                    \n",
    "                elif query_choice == \"5\":  # Collaborations\n",
    "                    print(f\"{i}. üë§ {record_dict['actor']}\")\n",
    "                    print(f\"   ü§ù {record_dict['collaborations']} collaboration(s)\")\n",
    "                    movies = record_dict.get('movies', [])\n",
    "                    if movies:\n",
    "                        print(f\"   üé¨ Films: {', '.join(movies)}\")\n",
    "                \n",
    "                print()\n",
    "            \n",
    "            # Helpful tip for genre queries\n",
    "            if query_choice == \"0\":\n",
    "                print(\"=\" * 70)\n",
    "                print(\"\\nüí° Tip: Copy genre names above to use in queries 1 and 4\")\n",
    "                print(\"   Example: Change query_choice to '1' and set:\")\n",
    "                print(f\"   \\\"params\\\": {{\\\"genre\\\": \\\"{records[0]['genre']}\\\"}}\")\n",
    "            \n",
    "            print(\"=\" * 70)\n",
    "            \n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è No results found\")\n",
    "            print(\"\\nüí° This could mean:\")\n",
    "            if query_choice != \"0\":\n",
    "                print(f\"   ‚Ä¢ No data matching: {query_info['params']}\")\n",
    "                print(\"   ‚Ä¢ Try query_choice='0' first to see available data\")\n",
    "            print(\"   ‚Ä¢ Database is empty (run Cell 5 to populate)\")\n",
    "            if query_choice == \"1\" or query_choice == \"4\":\n",
    "                print(\"   ‚Ä¢ Genre names might be in Vietnamese (check with query 0)\")\n",
    "            \n",
    "except NameError as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "    print(\"\\nüí° Please run Cell 2 first to load credentials\")\n",
    "    \n",
    "except Exception as e:\n",
    "    error_msg = str(e)\n",
    "    print(f\"‚ùå Query failed: {error_msg[:200]}\")\n",
    "    \n",
    "    print(\"\\nüí° Troubleshooting:\")\n",
    "    if \"authentication\" in error_msg.lower():\n",
    "        print(\"   ‚Ä¢ Wrong credentials - check NEO4J_USERNAME and NEO4J_PASSWORD\")\n",
    "    elif \"connection\" in error_msg.lower() or \"closed\" in error_msg.lower():\n",
    "        print(\"   ‚Ä¢ Connection lost - try running this cell again\")\n",
    "        print(\"   ‚Ä¢ Neo4j instance stopped - check Aura console\")\n",
    "        print(\"   ‚Ä¢ Wrong URI - verify NEO4J_URI is correct\")\n",
    "    else:\n",
    "        print(\"   ‚Ä¢ Database might be empty (run Cell 5 to populate)\")\n",
    "        print(\"   ‚Ä¢ Check if Neo4j instance is running\")\n",
    "        print(\"   ‚Ä¢ Visit: https://console.neo4j.io/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d730070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üìä DATABASE STATISTICS\n",
      "======================================================================\n",
      "\n",
      "1Ô∏è‚É£ QDRANT (Vector Database)\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üì¶ Collection: books_collection\n",
      "   ‚Ä¢ Total vectors: 0\n",
      "   ‚Ä¢ Vector size: 768\n",
      "   ‚Ä¢ Distance metric: Cosine\n",
      "\n",
      "üì¶ Collection: movies_vietnamese\n",
      "   ‚Ä¢ Total vectors: 701\n",
      "   ‚Ä¢ Vector size: 768\n",
      "   ‚Ä¢ Distance metric: Cosine\n",
      "\n",
      "   üìù Sample movies:\n",
      "      ‚Ä¢ Star Wars 4: Ni·ªÅm Hy V·ªçng M·ªõi (1977)\n",
      "      ‚Ä¢ ƒêi T√¨m Nemo (2003)\n",
      "      ‚Ä¢ Cu·ªôc ƒê·ªùi Forrest Gump (1994)\n",
      "\n",
      "üì¶ Collection: movies_graph_rag\n",
      "   ‚Ä¢ Total vectors: 0\n",
      "   ‚Ä¢ Vector size: 384\n",
      "   ‚Ä¢ Distance metric: Cosine\n",
      "\n",
      "\n",
      "2Ô∏è‚É£ NEO4J (Graph Database)\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üìä Node Statistics:\n",
      "   Total nodes: 3,739\n",
      "\n",
      "   Breakdown by type:\n",
      "      ‚Ä¢ Person: 3,015\n",
      "      ‚Ä¢ Movie: 705\n",
      "      ‚Ä¢ Genre: 19\n",
      "\n",
      "üìä Relationship Statistics:\n",
      "   Total relationships: 5,983\n",
      "\n",
      "   Breakdown by type:\n",
      "      ‚Ä¢ ACTED_IN: 3,373\n",
      "      ‚Ä¢ BELONGS_TO: 1,902\n",
      "      ‚Ä¢ DIRECTED: 708\n",
      "\n",
      "üé≠ Top 5 Genres:\n",
      "   1. Phim Ch√≠nh K·ªãch.....  280 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   2. Phim H√†nh ƒê·ªông......  223 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   3. Phim Phi√™u L∆∞u......  188 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   4. Phim G√¢y C·∫•n........  175 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   5. Phim H√†i............  162 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "‚≠ê Top 5 Highest Rated Movies:\n",
      "   1. Diabolisch (2025) - 10.0/10 ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê\n",
      "   2. Ph√° V·ª° S·ª± Im L·∫∑ng (2020) - 9.043/10 ‚≠ê‚≠ê‚≠ê‚≠ê\n",
      "   3. Ba L·∫ßn Ch·∫øt C·ªßa Marisela Escobedo (2020) - 8.8/10 ‚≠ê‚≠ê‚≠ê‚≠ê\n",
      "   4. ƒê·∫°i Chi·∫øn Ng∆∞·ªùi Kh·ªïng L·ªì: L·∫ßn T·∫•n C√¥ng Cu·ªëi C√πng (2024) - 8.755/10 ‚≠ê‚≠ê‚≠ê‚≠ê\n",
      "   5. Succubus (2024) - 8.748/10 ‚≠ê‚≠ê‚≠ê‚≠ê\n",
      "\n",
      "======================================================================\n",
      "\n",
      "üí° Tips:\n",
      "   ‚Ä¢ If databases are empty, run Cell 5 to crawl and populate data\n",
      "   ‚Ä¢ Increase MAX_PAGES in Cell 5 for more movies\n",
      "   ‚Ä¢ Check Cell 3 for connection troubleshooting\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# üìä Database Statistics & Health Check\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"üìä DATABASE STATISTICS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ===== QDRANT STATS =====\n",
    "print(\"\\n1Ô∏è‚É£ QDRANT (Vector Database)\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "try:\n",
    "    if 'q_client' not in locals() and 'qdrant_client' in locals():\n",
    "        q_client = qdrant_client\n",
    "    \n",
    "    if 'q_client' in locals():\n",
    "        collections = q_client.get_collections()\n",
    "        \n",
    "        if collections.collections:\n",
    "            for coll in collections.collections:\n",
    "                info = q_client.get_collection(coll.name)\n",
    "                points = info.points_count if hasattr(info, 'points_count') else 0\n",
    "                \n",
    "                print(f\"\\nüì¶ Collection: {coll.name}\")\n",
    "                print(f\"   ‚Ä¢ Total vectors: {points:,}\")\n",
    "                print(f\"   ‚Ä¢ Vector size: {info.config.params.vectors.size}\")\n",
    "                print(f\"   ‚Ä¢ Distance metric: {info.config.params.vectors.distance}\")\n",
    "                \n",
    "                # Sample a few points\n",
    "                if points > 0:\n",
    "                    sample = q_client.scroll(\n",
    "                        collection_name=coll.name,\n",
    "                        limit=3,\n",
    "                        with_payload=True,\n",
    "                        with_vectors=False\n",
    "                    )[0]\n",
    "                    \n",
    "                    print(f\"\\n   üìù Sample movies:\")\n",
    "                    for point in sample:\n",
    "                        title = point.payload.get('title', 'N/A')\n",
    "                        year = point.payload.get('year', 'N/A')\n",
    "                        print(f\"      ‚Ä¢ {title} ({year})\")\n",
    "        else:\n",
    "            print(\"   ‚ö†Ô∏è No collections found\")\n",
    "    else:\n",
    "        print(\"   ‚ùå Not connected (run Cell 4)\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"   ‚ùå Error: {str(e)[:150]}\")\n",
    "\n",
    "# ===== NEO4J STATS =====\n",
    "print(\"\\n\\n2Ô∏è‚É£ NEO4J (Graph Database)\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "try:\n",
    "    if 'n_driver' not in locals():\n",
    "        from neo4j import GraphDatabase\n",
    "        n_driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD))\n",
    "    \n",
    "    with n_driver.session() as session:\n",
    "        # Count nodes\n",
    "        stats_query = \"\"\"\n",
    "        MATCH (n)\n",
    "        WITH labels(n) as label, count(*) as count\n",
    "        UNWIND label as l\n",
    "        RETURN l, sum(count) as total\n",
    "        ORDER BY total DESC\n",
    "        \"\"\"\n",
    "        \n",
    "        result = session.run(stats_query)\n",
    "        node_stats = list(result)\n",
    "        \n",
    "        if node_stats:\n",
    "            print(\"\\nüìä Node Statistics:\")\n",
    "            total_nodes = sum(r['total'] for r in node_stats)\n",
    "            print(f\"   Total nodes: {total_nodes:,}\")\n",
    "            print(\"\\n   Breakdown by type:\")\n",
    "            for record in node_stats:\n",
    "                print(f\"      ‚Ä¢ {record['l']}: {record['total']:,}\")\n",
    "        \n",
    "        # Count relationships\n",
    "        rel_query = \"\"\"\n",
    "        MATCH ()-[r]->()\n",
    "        RETURN type(r) as rel_type, count(r) as count\n",
    "        ORDER BY count DESC\n",
    "        \"\"\"\n",
    "        \n",
    "        result = session.run(rel_query)\n",
    "        rel_stats = list(result)\n",
    "        \n",
    "        if rel_stats:\n",
    "            total_rels = sum(r['count'] for r in rel_stats)\n",
    "            print(f\"\\nüìä Relationship Statistics:\")\n",
    "            print(f\"   Total relationships: {total_rels:,}\")\n",
    "            print(\"\\n   Breakdown by type:\")\n",
    "            for record in rel_stats:\n",
    "                print(f\"      ‚Ä¢ {record['rel_type']}: {record['count']:,}\")\n",
    "        \n",
    "        # Top genres\n",
    "        genre_query = \"\"\"\n",
    "        MATCH (g:Genre)<-[:BELONGS_TO]-(m:Movie)\n",
    "        RETURN g.name as genre, count(m) as count\n",
    "        ORDER BY count DESC\n",
    "        LIMIT 5\n",
    "        \"\"\"\n",
    "        \n",
    "        result = session.run(genre_query)\n",
    "        genres = list(result)\n",
    "        \n",
    "        if genres:\n",
    "            print(f\"\\nüé≠ Top 5 Genres:\")\n",
    "            for i, record in enumerate(genres, 1):\n",
    "                bar = \"‚ñà\" * int(record['count'] / genres[0]['count'] * 20)\n",
    "                print(f\"   {i}. {record['genre']:.<20} {record['count']:>4} {bar}\")\n",
    "        \n",
    "        # Sample movies\n",
    "        sample_query = \"\"\"\n",
    "        MATCH (m:Movie)\n",
    "        RETURN m.title as title, m.year as year, m.rating as rating\n",
    "        ORDER BY m.rating DESC\n",
    "        LIMIT 5\n",
    "        \"\"\"\n",
    "        \n",
    "        result = session.run(sample_query)\n",
    "        samples = list(result)\n",
    "        \n",
    "        if samples:\n",
    "            print(f\"\\n‚≠ê Top 5 Highest Rated Movies:\")\n",
    "            for i, record in enumerate(samples, 1):\n",
    "                title = record['title']\n",
    "                year = record['year']\n",
    "                rating = record.get('rating', 0)\n",
    "                stars = \"‚≠ê\" * int(rating / 2) if rating else \"\"\n",
    "                print(f\"   {i}. {title} ({year}) - {rating}/10 {stars}\")\n",
    "        \n",
    "        if not node_stats:\n",
    "            print(\"   ‚ö†Ô∏è Database is empty (run Cell 5 to populate)\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"   ‚ùå Error: {str(e)[:150]}\")\n",
    "    print(\"   üí° Make sure Neo4j is connected (run Cell 3 for troubleshooting)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"\\nüí° Tips:\")\n",
    "print(\"   ‚Ä¢ If databases are empty, run Cell 5 to crawl and populate data\")\n",
    "print(\"   ‚Ä¢ Increase MAX_PAGES in Cell 5 for more movies\")\n",
    "print(\"   ‚Ä¢ Check Cell 3 for connection troubleshooting\")\n",
    "print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce908a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîç ENHANCED GRAPH ANALYSIS - Visualize Rich Connections\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"üï∏Ô∏è ENHANCED GRAPH ANALYSIS - Rich Connections & Insights\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "try:\n",
    "    if 'n_driver' not in locals():\n",
    "        from neo4j import GraphDatabase\n",
    "        n_driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD))\n",
    "    \n",
    "    with n_driver.session() as session:\n",
    "        \n",
    "        # ===== 1. NODE TYPE DISTRIBUTION =====\n",
    "        print(\"\\n1Ô∏è‚É£ NODE TYPE DISTRIBUTION\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        node_stats = session.run(\"\"\"\n",
    "            MATCH (n)\n",
    "            WITH labels(n)[0] as label, count(*) as count\n",
    "            RETURN label, count\n",
    "            ORDER BY count DESC\n",
    "        \"\"\")\n",
    "        \n",
    "        total_nodes = 0\n",
    "        for record in node_stats:\n",
    "            count = record['count']\n",
    "            total_nodes += count\n",
    "            label = record['label']\n",
    "            bar = \"‚ñà\" * int(count / 10)\n",
    "            print(f\"   {label:.<20} {count:>6,} {bar}\")\n",
    "        \n",
    "        print(f\"\\n   {'TOTAL':.<20} {total_nodes:>6,}\")\n",
    "        \n",
    "        # ===== 2. RELATIONSHIP TYPE DISTRIBUTION =====\n",
    "        print(\"\\n\\n2Ô∏è‚É£ RELATIONSHIP TYPE DISTRIBUTION\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        rel_stats = session.run(\"\"\"\n",
    "            MATCH ()-[r]->()\n",
    "            RETURN type(r) as rel_type, count(r) as count\n",
    "            ORDER BY count DESC\n",
    "        \"\"\")\n",
    "        \n",
    "        total_rels = 0\n",
    "        for record in rel_stats:\n",
    "            count = record['count']\n",
    "            total_rels += count\n",
    "            rel_type = record['rel_type']\n",
    "            bar = \"‚ñà\" * int(count / 20)\n",
    "            print(f\"   {rel_type:.<25} {count:>6,} {bar}\")\n",
    "        \n",
    "        print(f\"\\n   {'TOTAL':.<25} {total_rels:>6,}\")\n",
    "        \n",
    "        # ===== 3. TOP COLLABORATORS (WORKED_WITH) =====\n",
    "        print(\"\\n\\n3Ô∏è‚É£ TOP COLLABORATIONS (Most Frequent)\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        collab_stats = session.run(\"\"\"\n",
    "            MATCH (p1:Person)-[r:WORKED_WITH]-(p2:Person)\n",
    "            WHERE p1.id < p2.id\n",
    "            RETURN p1.name as person1, p2.name as person2, \n",
    "                   r.count as collaborations,\n",
    "                   r.movies[..3] as sample_movies\n",
    "            ORDER BY r.count DESC\n",
    "            LIMIT 10\n",
    "        \"\"\")\n",
    "        \n",
    "        for i, record in enumerate(collab_stats, 1):\n",
    "            print(f\"\\n   {i}. {record['person1']} ‚ÜîÔ∏è {record['person2']}\")\n",
    "            print(f\"      ü§ù {record['collaborations']} collaboration(s)\")\n",
    "            if record['sample_movies']:\n",
    "                print(f\"      üé¨ {', '.join(record['sample_movies'])}\")\n",
    "        \n",
    "        # ===== 4. TOP CO-STARS =====\n",
    "        print(\"\\n\\n4Ô∏è‚É£ TOP CO-STAR PAIRS\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        costar_stats = session.run(\"\"\"\n",
    "            MATCH (a1:Person)-[r:CO_STARRED]-(a2:Person)\n",
    "            WHERE a1.id < a2.id\n",
    "            RETURN a1.name as actor1, a2.name as actor2,\n",
    "                   r.count as movies_together,\n",
    "                   r.movies[..3] as sample_movies\n",
    "            ORDER BY r.count DESC\n",
    "            LIMIT 10\n",
    "        \"\"\")\n",
    "        \n",
    "        for i, record in enumerate(costar_stats, 1):\n",
    "            print(f\"\\n   {i}. {record['actor1']} & {record['actor2']}\")\n",
    "            print(f\"      üé≠ {record['movies_together']} movie(s) together\")\n",
    "            if record['sample_movies']:\n",
    "                print(f\"      üé¨ {', '.join(record['sample_movies'])}\")\n",
    "        \n",
    "        # ===== 5. MOST CONNECTED PEOPLE (by degree) =====\n",
    "        print(\"\\n\\n5Ô∏è‚É£ MOST CONNECTED PEOPLE (Highest Degree)\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        degree_stats = session.run(\"\"\"\n",
    "            MATCH (p:Person)\n",
    "            WITH p, size((p)-[]-()) as degree\n",
    "            WHERE degree > 0\n",
    "            ORDER BY degree DESC\n",
    "            LIMIT 10\n",
    "            MATCH (p)-[r]->(m:Movie)\n",
    "            WITH p, degree, type(r) as rel_type, count(m) as count\n",
    "            RETURN p.name as person, degree,\n",
    "                   collect({type: rel_type, count: count}) as connections\n",
    "        \"\"\")\n",
    "        \n",
    "        for i, record in enumerate(degree_stats, 1):\n",
    "            print(f\"\\n   {i}. {record['person']}\")\n",
    "            print(f\"      üîó Total degree: {record['degree']}\")\n",
    "            conn_details = record['connections']\n",
    "            if conn_details:\n",
    "                for conn in conn_details[:3]:  # Show top 3 connection types\n",
    "                    print(f\"         ‚Ä¢ {conn['type']}: {conn['count']}\")\n",
    "        \n",
    "        # ===== 6. KEYWORD CLUSTERS =====\n",
    "        print(\"\\n\\n6Ô∏è‚É£ MOST COMMON KEYWORDS\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        keyword_stats = session.run(\"\"\"\n",
    "            MATCH (k:Keyword)<-[:HAS_KEYWORD]-(m:Movie)\n",
    "            RETURN k.name as keyword, count(m) as movie_count\n",
    "            ORDER BY movie_count DESC\n",
    "            LIMIT 15\n",
    "        \"\"\")\n",
    "        \n",
    "        for i, record in enumerate(keyword_stats, 1):\n",
    "            count = record['movie_count']\n",
    "            keyword = record['keyword']\n",
    "            bar = \"‚ñà\" * min(int(count / 2), 30)\n",
    "            print(f\"   {i:2d}. {keyword:.<30} {count:>4} {bar}\")\n",
    "        \n",
    "        # ===== 7. PRODUCTION COMPANY INFLUENCE =====\n",
    "        print(\"\\n\\n7Ô∏è‚É£ TOP PRODUCTION COMPANIES\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        company_stats = session.run(\"\"\"\n",
    "            MATCH (c:Company)-[:PRODUCED]->(m:Movie)\n",
    "            WITH c, count(m) as movie_count, avg(m.rating) as avg_rating\n",
    "            WHERE movie_count >= 3\n",
    "            RETURN c.name as company, movie_count, avg_rating\n",
    "            ORDER BY movie_count DESC\n",
    "            LIMIT 10\n",
    "        \"\"\")\n",
    "        \n",
    "        for i, record in enumerate(company_stats, 1):\n",
    "            print(f\"\\n   {i}. {record['company']}\")\n",
    "            print(f\"      üé¨ {record['movie_count']} movies\")\n",
    "            print(f\"      ‚≠ê Avg rating: {record['avg_rating']:.2f}/10\")\n",
    "        \n",
    "        # ===== 8. MOVIE SIMILARITY NETWORK =====\n",
    "        print(\"\\n\\n8Ô∏è‚É£ MOVIES WITH MOST SIMILARITIES\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        similar_stats = session.run(\"\"\"\n",
    "            MATCH (m:Movie)-[r:SIMILAR_TO]->(other:Movie)\n",
    "            WITH m, count(r) as similar_count\n",
    "            ORDER BY similar_count DESC\n",
    "            LIMIT 10\n",
    "            MATCH (m)-[:SIMILAR_TO]->(related:Movie)\n",
    "            RETURN m.title as movie, m.year as year, similar_count,\n",
    "                   collect(related.title)[..3] as similar_titles\n",
    "        \"\"\")\n",
    "        \n",
    "        for i, record in enumerate(similar_stats, 1):\n",
    "            print(f\"\\n   {i}. {record['movie']} ({record['year']})\")\n",
    "            print(f\"      üîó {record['similar_count']} similar movies\")\n",
    "            if record['similar_titles']:\n",
    "                print(f\"      üé¨ Examples: {', '.join(record['similar_titles'])}\")\n",
    "        \n",
    "        # ===== 9. MOVIE COLLECTIONS =====\n",
    "        print(\"\\n\\n9Ô∏è‚É£ LARGEST MOVIE COLLECTIONS/SERIES\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        collection_stats = session.run(\"\"\"\n",
    "            MATCH (col:Collection)<-[:IN_COLLECTION]-(m:Movie)\n",
    "            WITH col, collect(m.title) as movies, count(m) as count\n",
    "            ORDER BY count DESC\n",
    "            LIMIT 10\n",
    "            RETURN col.name as collection, count, movies[..5] as sample_movies\n",
    "        \"\"\")\n",
    "        \n",
    "        for i, record in enumerate(collection_stats, 1):\n",
    "            print(f\"\\n   {i}. {record['collection']}\")\n",
    "            print(f\"      üé¨ {record['count']} movies in collection\")\n",
    "            if record['sample_movies']:\n",
    "                print(f\"      üìΩÔ∏è  {', '.join(record['sample_movies'])}\")\n",
    "        \n",
    "        # ===== 10. MULTI-TALENTED PEOPLE =====\n",
    "        print(\"\\n\\nüîü MULTI-TALENTED PEOPLE (Multiple Roles)\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        multitalent_stats = session.run(\"\"\"\n",
    "            MATCH (p:Person)-[r]->(m:Movie)\n",
    "            WITH p, collect(DISTINCT type(r)) as roles, count(DISTINCT m) as movie_count\n",
    "            WHERE size(roles) >= 2\n",
    "            RETURN p.name as person, roles, movie_count\n",
    "            ORDER BY size(roles) DESC, movie_count DESC\n",
    "            LIMIT 10\n",
    "        \"\"\")\n",
    "        \n",
    "        for i, record in enumerate(multitalent_stats, 1):\n",
    "            roles = record['roles']\n",
    "            print(f\"\\n   {i}. {record['person']}\")\n",
    "            print(f\"      üé≠ Roles: {', '.join(roles)}\")\n",
    "            print(f\"      üé¨ {record['movie_count']} movies\")\n",
    "        \n",
    "        # ===== SUMMARY STATS =====\n",
    "        print(\"\\n\\n\" + \"=\" * 80)\n",
    "        print(\"üìä GRAPH SUMMARY\")\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"   ‚Ä¢ Total Nodes: {total_nodes:,}\")\n",
    "        print(f\"   ‚Ä¢ Total Relationships: {total_rels:,}\")\n",
    "        print(f\"   ‚Ä¢ Average Degree: {total_rels * 2 / max(total_nodes, 1):.2f}\")\n",
    "        print(f\"   ‚Ä¢ Graph Density: {total_rels / max((total_nodes * (total_nodes - 1)), 1):.6f}\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {str(e)[:200]}\")\n",
    "    print(\"\\nüí° Make sure Neo4j is connected and database is populated\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6119c709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üéØ ADVANCED GRAPH QUERIES - Using Rich Connections\n",
    "\n",
    "# Select a query type (change this number: 0-9)\n",
    "query_choice = \"0\"\n",
    "\n",
    "advanced_queries = {\n",
    "    \"0\": {\n",
    "        \"name\": \"Find Creative Teams (Director + Cinematographer + Composer)\",\n",
    "        \"cypher\": \"\"\"\n",
    "            MATCH (d:Person)-[:DIRECTED]->(m:Movie)<-[:CINEMATOGRAPHY]-(c:Person),\n",
    "                  (m)<-[:COMPOSED_MUSIC]-(comp:Person)\n",
    "            WHERE m.rating >= 7.5\n",
    "            RETURN d.name as director, \n",
    "                   c.name as cinematographer,\n",
    "                   comp.name as composer,\n",
    "                   collect(m.title)[..3] as movies,\n",
    "                   count(m) as collaborations\n",
    "            ORDER BY collaborations DESC\n",
    "            LIMIT 10\n",
    "        \"\"\",\n",
    "        \"params\": {}\n",
    "    },\n",
    "    \"1\": {\n",
    "        \"name\": \"Movies in Same Collection with Keywords\",\n",
    "        \"cypher\": \"\"\"\n",
    "            MATCH (m1:Movie)-[:IN_COLLECTION]->(col:Collection)<-[:IN_COLLECTION]-(m2:Movie)\n",
    "            WHERE m1.id < m2.id\n",
    "            MATCH (m1)-[:HAS_KEYWORD]->(k:Keyword)<-[:HAS_KEYWORD]-(m2)\n",
    "            RETURN col.name as collection,\n",
    "                   m1.title as movie1,\n",
    "                   m2.title as movie2,\n",
    "                   collect(DISTINCT k.name)[..5] as shared_keywords,\n",
    "                   abs(m1.rating - m2.rating) as rating_diff\n",
    "            ORDER BY size(shared_keywords) DESC\n",
    "            LIMIT 10\n",
    "        \"\"\",\n",
    "        \"params\": {}\n",
    "    },\n",
    "    \"2\": {\n",
    "        \"name\": \"Actor Career Path (by keywords over time)\",\n",
    "        \"cypher\": \"\"\"\n",
    "            MATCH (a:Person {name: $actor_name})-[:ACTED_IN]->(m:Movie)-[:HAS_KEYWORD]->(k:Keyword)\n",
    "            WITH a, m, k\n",
    "            ORDER BY m.year\n",
    "            RETURN m.year as year, \n",
    "                   m.title as movie,\n",
    "                   collect(DISTINCT k.name)[..5] as keywords,\n",
    "                   m.rating as rating\n",
    "            ORDER BY year\n",
    "        \"\"\",\n",
    "        \"params\": {\"actor_name\": \"Tom Hanks\"}\n",
    "    },\n",
    "    \"3\": {\n",
    "        \"name\": \"Director-Cinematographer Partnerships\",\n",
    "        \"cypher\": \"\"\"\n",
    "            MATCH (d:Person)-[:DIRECTED]->(m:Movie)<-[:CINEMATOGRAPHY]-(c:Person)\n",
    "            WITH d, c, collect(m) as movies\n",
    "            WHERE size(movies) >= 2\n",
    "            RETURN d.name as director,\n",
    "                   c.name as cinematographer,\n",
    "                   size(movies) as movies_together,\n",
    "                   [m IN movies | m.title][..3] as sample_movies,\n",
    "                   avg([m IN movies | m.rating]) as avg_rating\n",
    "            ORDER BY movies_together DESC, avg_rating DESC\n",
    "            LIMIT 10\n",
    "        \"\"\",\n",
    "        \"params\": {}\n",
    "    },\n",
    "    \"4\": {\n",
    "        \"name\": \"Company Production Patterns by Genre\",\n",
    "        \"cypher\": \"\"\"\n",
    "            MATCH (c:Company)-[:PRODUCED]->(m:Movie)-[:BELONGS_TO]->(g:Genre)\n",
    "            WHERE c.name = $company_name\n",
    "            WITH g, count(m) as movie_count, avg(m.rating) as avg_rating,\n",
    "                 sum(m.revenue) as total_revenue\n",
    "            RETURN g.name as genre,\n",
    "                   movie_count,\n",
    "                   round(avg_rating, 2) as avg_rating,\n",
    "                   total_revenue / 1000000 as revenue_millions\n",
    "            ORDER BY movie_count DESC\n",
    "        \"\"\",\n",
    "        \"params\": {\"company_name\": \"Warner Bros. Pictures\"}\n",
    "    },\n",
    "    \"5\": {\n",
    "        \"name\": \"Find Similar Movies through Keywords + Cast\",\n",
    "        \"cypher\": \"\"\"\n",
    "            MATCH (m:Movie {title: $movie_title})\n",
    "            MATCH (m)-[:HAS_KEYWORD]->(k:Keyword)<-[:HAS_KEYWORD]-(similar:Movie)\n",
    "            WHERE m <> similar\n",
    "            WITH m, similar, count(k) as keyword_overlap\n",
    "            OPTIONAL MATCH (m)<-[:ACTED_IN]-(a:Person)-[:ACTED_IN]->(similar)\n",
    "            WITH m, similar, keyword_overlap, count(a) as cast_overlap\n",
    "            WHERE keyword_overlap >= 2 OR cast_overlap >= 1\n",
    "            RETURN similar.title as title,\n",
    "                   similar.year as year,\n",
    "                   keyword_overlap,\n",
    "                   cast_overlap,\n",
    "                   (keyword_overlap * 2 + cast_overlap * 3) as similarity_score\n",
    "            ORDER BY similarity_score DESC\n",
    "            LIMIT 10\n",
    "        \"\"\",\n",
    "        \"params\": {\"movie_title\": \"Inception\"}\n",
    "    },\n",
    "    \"6\": {\n",
    "        \"name\": \"Actor Versatility (Different Genres)\",\n",
    "        \"cypher\": \"\"\"\n",
    "            MATCH (a:Person {name: $actor_name})-[:ACTED_IN]->(m:Movie)-[:BELONGS_TO]->(g:Genre)\n",
    "            WITH a, g, collect(m.title) as movies, count(m) as movie_count,\n",
    "                 avg(m.rating) as avg_rating\n",
    "            RETURN g.name as genre,\n",
    "                   movie_count,\n",
    "                   round(avg_rating, 2) as avg_rating,\n",
    "                   movies[..3] as sample_movies\n",
    "            ORDER BY movie_count DESC, avg_rating DESC\n",
    "        \"\"\",\n",
    "        \"params\": {\"actor_name\": \"Leonardo DiCaprio\"}\n",
    "    },\n",
    "    \"7\": {\n",
    "        \"name\": \"Find Movies by Keyword Combinations\",\n",
    "        \"cypher\": \"\"\"\n",
    "            MATCH (m:Movie)-[:HAS_KEYWORD]->(k1:Keyword {name: $keyword1})\n",
    "            MATCH (m)-[:HAS_KEYWORD]->(k2:Keyword {name: $keyword2})\n",
    "            OPTIONAL MATCH (d:Person)-[:DIRECTED]->(m)\n",
    "            OPTIONAL MATCH (m)-[:BELONGS_TO]->(g:Genre)\n",
    "            RETURN m.title as title, \n",
    "                   m.year as year,\n",
    "                   m.rating as rating,\n",
    "                   d.name as director,\n",
    "                   collect(DISTINCT g.name) as genres\n",
    "            ORDER BY m.rating DESC\n",
    "            LIMIT 10\n",
    "        \"\"\",\n",
    "        \"params\": {\"keyword1\": \"heist\", \"keyword2\": \"revenge\"}\n",
    "    },\n",
    "    \"8\": {\n",
    "        \"name\": \"Writer-Director-Actor Trios\",\n",
    "        \"cypher\": \"\"\"\n",
    "            MATCH (w:Person)-[:WROTE]->(m:Movie)<-[:DIRECTED]-(d:Person),\n",
    "                  (m)<-[:ACTED_IN]-(a:Person)\n",
    "            WHERE w <> d AND w <> a AND d <> a\n",
    "            WITH w, d, a, collect(m.title) as movies, count(m) as collab_count\n",
    "            WHERE collab_count >= 1\n",
    "            RETURN w.name as writer,\n",
    "                   d.name as director,\n",
    "                   a.name as actor,\n",
    "                   collab_count,\n",
    "                   movies[..3] as sample_movies\n",
    "            ORDER BY collab_count DESC\n",
    "            LIMIT 10\n",
    "        \"\"\",\n",
    "        \"params\": {}\n",
    "    },\n",
    "    \"9\": {\n",
    "        \"name\": \"Country Film Industry Analysis\",\n",
    "        \"cypher\": \"\"\"\n",
    "            MATCH (m:Movie)-[:FILMED_IN]->(c:Country {name: $country})\n",
    "            WITH c, count(m) as total_movies, \n",
    "                 avg(m.rating) as avg_rating,\n",
    "                 sum(m.revenue) as total_revenue\n",
    "            MATCH (m:Movie)-[:FILMED_IN]->(c)\n",
    "            MATCH (m)-[:BELONGS_TO]->(g:Genre)\n",
    "            WITH c, total_movies, avg_rating, total_revenue,\n",
    "                 g.name as genre, count(m) as genre_count\n",
    "            ORDER BY genre_count DESC\n",
    "            RETURN c.name as country,\n",
    "                   total_movies,\n",
    "                   round(avg_rating, 2) as avg_rating,\n",
    "                   total_revenue / 1000000 as revenue_millions,\n",
    "                   collect({genre: genre, count: genre_count})[..5] as top_genres\n",
    "        \"\"\",\n",
    "        \"params\": {\"country\": \"United States of America\"}\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"üéØ ADVANCED GRAPH QUERIES - Rich Connection Analysis\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nAvailable queries:\")\n",
    "for key, info in advanced_queries.items():\n",
    "    print(f\"  {key}. {info['name']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "query_info = advanced_queries[query_choice]\n",
    "print(f\"\\nüîç Running: {query_info['name']}\")\n",
    "if query_info['params']:\n",
    "    print(f\"üìä Parameters: {query_info['params']}\")\n",
    "print()\n",
    "\n",
    "try:\n",
    "    if 'n_driver' not in locals():\n",
    "        from neo4j import GraphDatabase\n",
    "        n_driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD))\n",
    "    \n",
    "    with n_driver.session() as session:\n",
    "        result = session.run(query_info['cypher'], query_info['params'])\n",
    "        records = list(result)\n",
    "        \n",
    "        if records:\n",
    "            print(\"=\" * 80)\n",
    "            print(f\"üìä RESULTS ({len(records)} found)\")\n",
    "            print(\"=\" * 80 + \"\\n\")\n",
    "            \n",
    "            for i, record in enumerate(records, 1):\n",
    "                record_dict = dict(record)\n",
    "                \n",
    "                # Display based on query type\n",
    "                if query_choice == \"0\":  # Creative Teams\n",
    "                    print(f\"{i}. üé• Director: {record_dict['director']}\")\n",
    "                    print(f\"   üì∑ Cinematographer: {record_dict['cinematographer']}\")\n",
    "                    print(f\"   üéµ Composer: {record_dict['composer']}\")\n",
    "                    print(f\"   ü§ù {record_dict['collaborations']} collaboration(s)\")\n",
    "                    if record_dict['movies']:\n",
    "                        print(f\"   üé¨ {', '.join(record_dict['movies'])}\")\n",
    "                \n",
    "                elif query_choice == \"1\":  # Collection Keywords\n",
    "                    print(f\"{i}. üì¶ {record_dict['collection']}\")\n",
    "                    print(f\"   üé¨ {record_dict['movie1']} ‚ÜîÔ∏è {record_dict['movie2']}\")\n",
    "                    print(f\"   üè∑Ô∏è  Shared: {', '.join(record_dict['shared_keywords'])}\")\n",
    "                    print(f\"   ‚≠ê Rating diff: {record_dict['rating_diff']:.1f}\")\n",
    "                \n",
    "                elif query_choice == \"2\":  # Career Path\n",
    "                    print(f\"{i}. {record_dict['year']} - {record_dict['movie']} ({record_dict['rating']:.1f}‚≠ê)\")\n",
    "                    print(f\"   üè∑Ô∏è  {', '.join(record_dict['keywords'])}\")\n",
    "                \n",
    "                elif query_choice == \"3\":  # Director-Cinematographer\n",
    "                    print(f\"{i}. {record_dict['director']} + {record_dict['cinematographer']}\")\n",
    "                    print(f\"   ü§ù {record_dict['movies_together']} movie(s)\")\n",
    "                    print(f\"   ‚≠ê Avg: {record_dict['avg_rating']:.2f}\")\n",
    "                    if record_dict['sample_movies']:\n",
    "                        print(f\"   üé¨ {', '.join(record_dict['sample_movies'])}\")\n",
    "                \n",
    "                elif query_choice == \"4\":  # Company Patterns\n",
    "                    print(f\"{i}. üìÇ {record_dict['genre']}\")\n",
    "                    print(f\"   üé¨ {record_dict['movie_count']} movies\")\n",
    "                    print(f\"   ‚≠ê Avg: {record_dict['avg_rating']}\")\n",
    "                    print(f\"   üí∞ ${record_dict['revenue_millions']:.1f}M\")\n",
    "                \n",
    "                elif query_choice == \"5\":  # Similar Movies\n",
    "                    print(f\"{i}. {record_dict['title']} ({record_dict['year']})\")\n",
    "                    print(f\"   üè∑Ô∏è  Keyword overlap: {record_dict['keyword_overlap']}\")\n",
    "                    print(f\"   üë• Cast overlap: {record_dict['cast_overlap']}\")\n",
    "                    print(f\"   üìä Score: {record_dict['similarity_score']}\")\n",
    "                \n",
    "                elif query_choice == \"6\":  # Actor Versatility\n",
    "                    print(f\"{i}. üìÇ {record_dict['genre']}\")\n",
    "                    print(f\"   üé¨ {record_dict['movie_count']} movies\")\n",
    "                    print(f\"   ‚≠ê Avg: {record_dict['avg_rating']}\")\n",
    "                    if record_dict['sample_movies']:\n",
    "                        print(f\"   üé• {', '.join(record_dict['sample_movies'])}\")\n",
    "                \n",
    "                elif query_choice == \"7\":  # Keyword Combinations\n",
    "                    print(f\"{i}. {record_dict['title']} ({record_dict['year']}) - {record_dict['rating']:.1f}‚≠ê\")\n",
    "                    if record_dict.get('director'):\n",
    "                        print(f\"   üé• {record_dict['director']}\")\n",
    "                    if record_dict['genres']:\n",
    "                        print(f\"   üìÇ {', '.join(record_dict['genres'])}\")\n",
    "                \n",
    "                elif query_choice == \"8\":  # Writer-Director-Actor Trios\n",
    "                    print(f\"{i}. ‚úçÔ∏è  {record_dict['writer']} | üé• {record_dict['director']} | üé≠ {record_dict['actor']}\")\n",
    "                    print(f\"   ü§ù {record_dict['collab_count']} collaboration(s)\")\n",
    "                    if record_dict['sample_movies']:\n",
    "                        print(f\"   üé¨ {', '.join(record_dict['sample_movies'])}\")\n",
    "                \n",
    "                elif query_choice == \"9\":  # Country Analysis\n",
    "                    print(f\"{i}. üåç {record_dict['country']}\")\n",
    "                    print(f\"   üé¨ {record_dict['total_movies']} movies\")\n",
    "                    print(f\"   ‚≠ê Avg: {record_dict['avg_rating']}\")\n",
    "                    print(f\"   üí∞ ${record_dict['revenue_millions']:.1f}M\")\n",
    "                    if record_dict['top_genres']:\n",
    "                        print(f\"   üìÇ Top genres:\")\n",
    "                        for genre_info in record_dict['top_genres'][:3]:\n",
    "                            print(f\"      ‚Ä¢ {genre_info['genre']}: {genre_info['count']}\")\n",
    "                \n",
    "                print()\n",
    "            \n",
    "            print(\"=\" * 80)\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è No results found\")\n",
    "            print(\"\\nüí° Tips:\")\n",
    "            print(\"   ‚Ä¢ Database might be empty (run Cell 5 to populate)\")\n",
    "            print(\"   ‚Ä¢ Try different parameters\")\n",
    "            print(\"   ‚Ä¢ Check available data with previous cells\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Query failed: {str(e)[:200]}\")\n",
    "    print(\"\\nüí° Make sure Neo4j is connected and database is populated\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d0b407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìÅ Preview Saved Local Data - For UI/UX Development\n",
    "\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "data_dir = '../crawled_data'\n",
    "index_file = f'{data_dir}/movies_index.json'\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"üìÅ SAVED DATA PREVIEW - For UI/UX Development\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "try:\n",
    "    # Check if data exists\n",
    "    if not os.path.exists(data_dir):\n",
    "        print(\"\\n‚ö†Ô∏è  No data found. Please run Cell 6 (crawl pipeline) first.\")\n",
    "    else:\n",
    "        # Load index\n",
    "        if os.path.exists(index_file):\n",
    "            with open(index_file, 'r', encoding='utf-8') as f:\n",
    "                index_data = json.load(f)\n",
    "            \n",
    "            print(f\"\\nüìä Data Summary:\")\n",
    "            print(f\"   ‚Ä¢ Total movies: {index_data['total_movies']}\")\n",
    "            print(f\"   ‚Ä¢ Crawl date: {index_data['crawl_date']}\")\n",
    "            print(f\"   ‚Ä¢ Location: {data_dir}/\")\n",
    "            \n",
    "            # Show folder structure\n",
    "            print(f\"\\nüìÇ Folder Structure:\")\n",
    "            print(f\"   {data_dir}/\")\n",
    "            print(f\"   ‚îú‚îÄ‚îÄ movies/          ({len(os.listdir(f'{data_dir}/movies'))} files)\")\n",
    "            print(f\"   ‚îú‚îÄ‚îÄ posters/         ({len(os.listdir(f'{data_dir}/posters'))} files)\")\n",
    "            print(f\"   ‚îî‚îÄ‚îÄ movies_index.json (master index)\")\n",
    "            \n",
    "            # Show top 10 movies\n",
    "            movies = index_data['movies'][:10]\n",
    "            \n",
    "            print(f\"\\nüé¨ Top 10 Movies (by rating):\")\n",
    "            print(\"-\" * 80)\n",
    "            \n",
    "            for i, movie in enumerate(movies, 1):\n",
    "                title = movie['title']\n",
    "                year = movie['year']\n",
    "                rating = movie['rating']\n",
    "                genres = ', '.join(movie['genres'][:3])\n",
    "                poster = \"‚úÖ\" if movie.get('poster_url') else \"‚ùå\"\n",
    "                \n",
    "                print(f\"\\n{i:2d}. {title} ({year}) - {rating:.1f}‚≠ê\")\n",
    "                print(f\"    üìÇ {genres}\")\n",
    "                print(f\"    üñºÔ∏è  Poster: {poster}\")\n",
    "                if movie.get('poster_url'):\n",
    "                    print(f\"    üîó {movie['poster_url']}\")\n",
    "            \n",
    "            # Show sample data structure\n",
    "            print(f\"\\n\\nüìã Sample Movie Data Structure:\")\n",
    "            print(\"-\" * 80)\n",
    "            \n",
    "            sample_file = movies[0]['file']\n",
    "            sample_path = f\"{data_dir}/movies/{sample_file}\"\n",
    "            \n",
    "            with open(sample_path, 'r', encoding='utf-8') as f:\n",
    "                sample_data = json.load(f)\n",
    "            \n",
    "            # Show available fields\n",
    "            movie_fields = sample_data.get('movie', {}).keys()\n",
    "            credits_fields = sample_data.get('credits', {}).keys()\n",
    "            \n",
    "            print(f\"\\nüìÑ Movie Object Fields ({len(movie_fields)} fields):\")\n",
    "            print(f\"   {', '.join(list(movie_fields)[:15])}...\")\n",
    "            \n",
    "            print(f\"\\nüë• Credits Object Fields ({len(credits_fields)} fields):\")\n",
    "            print(f\"   {', '.join(list(credits_fields))}\")\n",
    "            \n",
    "            # Show keywords and similar\n",
    "            keywords = sample_data.get('keywords', {}).get('keywords', [])\n",
    "            similar = sample_data.get('similar', {}).get('results', [])\n",
    "            \n",
    "            print(f\"\\nüè∑Ô∏è  Keywords: {len(keywords)} found\")\n",
    "            if keywords:\n",
    "                print(f\"   Examples: {', '.join([k['name'] for k in keywords[:5]])}\")\n",
    "            \n",
    "            print(f\"\\nüîó Similar Movies: {len(similar)} found\")\n",
    "            if similar:\n",
    "                print(f\"   Examples: {', '.join([s['title'] for s in similar[:3]])}\")\n",
    "            \n",
    "            # Usage tips\n",
    "            print(f\"\\n\\nüí° Usage Tips for UI/UX Development:\")\n",
    "            print(\"-\" * 80)\n",
    "            print(\"1. Load movies_index.json for quick overview and pagination\")\n",
    "            print(\"2. Load individual movie JSON files for detailed information\")\n",
    "            print(\"3. Poster URLs are ready to use (just add to <img> tags)\")\n",
    "            print(\"4. All data is in JSON format - easy to parse and display\")\n",
    "            print(\"5. Files are organized by TMDB ID (e.g., movies/550.json)\")\n",
    "            \n",
    "            print(f\"\\nüìù Example Code:\")\n",
    "            print(\"-\" * 80)\n",
    "            print(\"\"\"\n",
    "# Load index\n",
    "with open('crawled_data/movies_index.json', 'r') as f:\n",
    "    index = json.load(f)\n",
    "\n",
    "# Get top movies\n",
    "top_movies = index['movies'][:20]\n",
    "\n",
    "# Load detailed data for a movie\n",
    "movie_id = top_movies[0]['id']\n",
    "with open(f'crawled_data/movies/{movie_id}.json', 'r') as f:\n",
    "    movie_data = json.load(f)\n",
    "\n",
    "# Access movie info\n",
    "title = movie_data['movie']['title']\n",
    "poster = movie_data['movie']['poster_path']\n",
    "cast = [c['name'] for c in movie_data['credits']['cast'][:5]]\n",
    "keywords = [k['name'] for k in movie_data['keywords']['keywords']]\n",
    "            \"\"\")\n",
    "            \n",
    "        else:\n",
    "            print(\"\\n‚ö†Ô∏è  Index file not found. Crawl might be incomplete.\")\n",
    "            print(f\"   Expected: {index_file}\")\n",
    "            \n",
    "            # Show what exists\n",
    "            movies_dir = f\"{data_dir}/movies\"\n",
    "            if os.path.exists(movies_dir):\n",
    "                movie_count = len([f for f in os.listdir(movies_dir) if f.endswith('.json')])\n",
    "                print(f\"\\nüìä Found {movie_count} movie files in {movies_dir}/\")\n",
    "            \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Error: {str(e)[:200]}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e07ed15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üé® Helper Functions for RAG System - Format Movie Results with Posters\n",
    "\n",
    "def format_movie_for_display(movie_data, include_poster=True):\n",
    "    \"\"\"\n",
    "    Format movie data for beautiful display in RAG responses\n",
    "    Returns a dict with all needed info including poster URL\n",
    "    \"\"\"\n",
    "    result = {\n",
    "        'id': movie_data.get('tmdb_id') or movie_data.get('id'),\n",
    "        'title': movie_data.get('title', 'Unknown'),\n",
    "        'year': movie_data.get('year', 'N/A'),\n",
    "        'rating': movie_data.get('rating', 0),\n",
    "        'genres': movie_data.get('genres', []),\n",
    "        'overview': movie_data.get('overview', '')[:200] + '...' if len(movie_data.get('overview', '')) > 200 else movie_data.get('overview', ''),\n",
    "    }\n",
    "    \n",
    "    if include_poster:\n",
    "        result['poster_url'] = movie_data.get('poster_url')\n",
    "        result['backdrop_url'] = movie_data.get('backdrop_url')\n",
    "    \n",
    "    return result\n",
    "\n",
    "def create_movie_card_json(movies):\n",
    "    \"\"\"\n",
    "    Create JSON array of movie cards ready for UI display\n",
    "    Perfect for RAG system to return when recommending movies\n",
    "    \"\"\"\n",
    "    import json\n",
    "    \n",
    "    cards = []\n",
    "    for movie in movies:\n",
    "        card = {\n",
    "            'id': movie.get('tmdb_id') or movie.get('id'),\n",
    "            'title': movie.get('title'),\n",
    "            'year': movie.get('year'),\n",
    "            'rating': float(movie.get('rating', 0)),\n",
    "            'genres': movie.get('genres', [])[:3],  # Top 3 genres\n",
    "            'poster': movie.get('poster_url'),\n",
    "            'backdrop': movie.get('backdrop_url')\n",
    "        }\n",
    "        cards.append(card)\n",
    "    \n",
    "    return json.dumps(cards, ensure_ascii=False, indent=2)\n",
    "\n",
    "def get_movie_with_poster_from_qdrant(query_text, limit=5):\n",
    "    \"\"\"\n",
    "    Search movies in Qdrant and return results with poster URLs ready for display\n",
    "    \"\"\"\n",
    "    import google.generativeai as genai\n",
    "    \n",
    "    # Create query embedding\n",
    "    result = genai.embed_content(\n",
    "        model=\"models/text-embedding-004\",\n",
    "        content=query_text,\n",
    "        task_type=\"retrieval_query\"\n",
    "    )\n",
    "    query_vector = result['embedding']\n",
    "    \n",
    "    # Search Qdrant\n",
    "    results = q_client.search(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        query_vector=query_vector,\n",
    "        limit=limit,\n",
    "        with_payload=True\n",
    "    )\n",
    "    \n",
    "    # Format results with posters\n",
    "    movies = []\n",
    "    for hit in results:\n",
    "        movie = {\n",
    "            'id': hit.payload.get('tmdb_id'),\n",
    "            'title': hit.payload.get('title'),\n",
    "            'year': hit.payload.get('year'),\n",
    "            'rating': hit.payload.get('rating'),\n",
    "            'genres': hit.payload.get('genres', []),\n",
    "            'poster_url': hit.payload.get('poster_url'),\n",
    "            'backdrop_url': hit.payload.get('backdrop_url'),\n",
    "            'overview': hit.payload.get('overview'),\n",
    "            'score': hit.score\n",
    "        }\n",
    "        movies.append(movie)\n",
    "    \n",
    "    return movies\n",
    "\n",
    "def get_movie_with_poster_from_neo4j(movie_id):\n",
    "    \"\"\"\n",
    "    Get movie details from Neo4j including poster URL\n",
    "    \"\"\"\n",
    "    with n_driver.session() as session:\n",
    "        result = session.run(\"\"\"\n",
    "            MATCH (m:Movie {id: $id})\n",
    "            OPTIONAL MATCH (d:Person)-[:DIRECTED]->(m)\n",
    "            OPTIONAL MATCH (a:Person)-[:ACTED_IN]->(m)\n",
    "            OPTIONAL MATCH (m)-[:BELONGS_TO]->(g:Genre)\n",
    "            RETURN m.id as id,\n",
    "                   m.title as title,\n",
    "                   m.year as year,\n",
    "                   m.rating as rating,\n",
    "                   m.poster_url as poster_url,\n",
    "                   m.backdrop_url as backdrop_url,\n",
    "                   m.overview as overview,\n",
    "                   collect(DISTINCT d.name)[..3] as directors,\n",
    "                   collect(DISTINCT a.name)[..5] as cast,\n",
    "                   collect(DISTINCT g.name) as genres\n",
    "        \"\"\", id=movie_id)\n",
    "        \n",
    "        record = result.single()\n",
    "        if not record:\n",
    "            return None\n",
    "        \n",
    "        return dict(record)\n",
    "\n",
    "# Example usage\n",
    "print(\"=\" * 80)\n",
    "print(\"üé® RAG DISPLAY HELPERS - Test Functions\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Test 1: Search and format movies\n",
    "print(\"\\n1Ô∏è‚É£ Testing vector search with poster URLs...\")\n",
    "try:\n",
    "    movies = get_movie_with_poster_from_qdrant(\"action movies with Tom Hanks\", limit=3)\n",
    "    \n",
    "    print(f\"\\nFound {len(movies)} movies:\\n\")\n",
    "    for i, movie in enumerate(movies, 1):\n",
    "        print(f\"{i}. {movie['title']} ({movie['year']}) - ‚≠ê {movie['rating']:.1f}\")\n",
    "        print(f\"   üìä Score: {movie['score']:.3f}\")\n",
    "        print(f\"   üñºÔ∏è  Poster: {movie['poster_url'][:50]}...\" if movie['poster_url'] else \"   üñºÔ∏è  No poster\")\n",
    "        print(f\"   üé¨ Genres: {', '.join(movie['genres'][:3])}\")\n",
    "        print()\n",
    "    \n",
    "    # Create JSON for UI\n",
    "    print(\"üì¶ JSON for UI/RAG System:\")\n",
    "    print(\"-\" * 80)\n",
    "    json_output = create_movie_card_json(movies)\n",
    "    print(json_output[:500] + \"...\" if len(json_output) > 500 else json_output)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"   ‚ö†Ô∏è Error: {str(e)[:150]}\")\n",
    "    print(\"   üí° Make sure Qdrant has data (run crawl first)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úÖ Functions ready for RAG system integration!\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nüí° Usage in RAG Pipeline:\")\n",
    "print(\"-\" * 80)\n",
    "print(\"\"\"\n",
    "# When user asks for recommendations:\n",
    "user_query = \"Recommend me action movies\"\n",
    "\n",
    "# 1. Search with posters\n",
    "movies = get_movie_with_poster_from_qdrant(user_query, limit=5)\n",
    "\n",
    "# 2. Format for display\n",
    "json_data = create_movie_card_json(movies)\n",
    "\n",
    "# 3. Return to UI with posters\n",
    "response = {\n",
    "    'text': 'Here are some great action movies:',\n",
    "    'movies': json_data,  # ‚Üê UI can display this with posters!\n",
    "    'display_mode': 'cards'\n",
    "}\n",
    "\n",
    "# Frontend receives:\n",
    "# [\n",
    "#   {\n",
    "#     \"id\": 550,\n",
    "#     \"title\": \"Fight Club\",\n",
    "#     \"poster\": \"https://image.tmdb.org/t/p/w500/...\",\n",
    "#     \"rating\": 8.4\n",
    "#   },\n",
    "#   ...\n",
    "# ]\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfff08e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üî¨ HYBRID SEARCH COMPARISON\n",
      "======================================================================\n",
      "\n",
      "üîç Query: \"Phim h√†nh ƒë·ªông c·ªßa Christopher Nolan\"\n",
      "\n",
      "1Ô∏è‚É£ VECTOR SEARCH (Semantic Similarity)\n",
      "----------------------------------------------------------------------\n",
      "‚ö° Time: 308.3ms | Found: 5 movies\n",
      "\n",
      "   1. Ng∆∞·ªùi D∆°i B·∫Øt ƒê·∫ßu (2005) - Score: 0.733\n",
      "   2. K·ªµ Sƒ© B√≥ng ƒê√™m (2008) - Score: 0.696\n",
      "   3. K·ªµ Sƒ© B√≥ng ƒê√™m Tr·ªói D·∫≠y (2012) - Score: 0.684\n",
      "   4. Th·ª£ L·ª£p M√°i (2025) - Score: 0.674\n",
      "   5. ·∫¢o Thu·∫≠t Gia ƒê·∫•u Tr√≠ (2006) - Score: 0.653\n",
      "\n",
      "\n",
      "2Ô∏è‚É£ GRAPH SEARCH (Structured Query)\n",
      "----------------------------------------------------------------------\n",
      "‚ö° Time: 310.5ms | Found: 5 movies\n",
      "\n",
      "   1. K·ªµ Sƒ© B√≥ng ƒê√™m (2008) - Director: Christopher Nolan - Rating: 8.525/10\n",
      "   2. H·ªë ƒêen T·ª≠ Th·∫ßn (2014) - Director: Christopher Nolan - Rating: 8.465/10\n",
      "   3. K·∫ª C·∫Øp Gi·∫•c M∆° (2010) - Director: Christopher Nolan - Rating: 8.371/10\n",
      "   4. ·∫¢o Thu·∫≠t Gia ƒê·∫•u Tr√≠ (2006) - Director: Christopher Nolan - Rating: 8.206/10\n",
      "   5. K·∫ª M·∫•t Tr√≠ Nh·ªõ (2000) - Director: Christopher Nolan - Rating: 8.178/10\n",
      "\n",
      "\n",
      "3Ô∏è‚É£ HYBRID APPROACH (Vector + Graph Enrichment)\n",
      "----------------------------------------------------------------------\n",
      "‚ö° Time: 849.5ms | Enriched: 3 movies\n",
      "\n",
      "   1. K·ªµ Sƒ© B√≥ng ƒê√™m (2008)\n",
      "      üé• Director: Christopher Nolan\n",
      "      üë• Cast: Michael Caine, Christian Bale, Heath Ledger\n",
      "      üìÇ Genres: Phim G√¢y C·∫•n, Phim H√¨nh S·ª±, Phim H√†nh ƒê·ªông, Phim Ch√≠nh K·ªãch\n",
      "      üé¨ Director's other works: H·ªë ƒêen T·ª≠ Th·∫ßn, K·∫ª C·∫Øp Gi·∫•c M∆°, Oppenheimer\n",
      "\n",
      "   2. K·ªµ Sƒ© B√≥ng ƒê√™m Tr·ªói D·∫≠y (2012)\n",
      "      üé• Director: Christopher Nolan\n",
      "      üë• Cast: Anne Hathaway, Joseph Gordon-Levitt, Tom Hardy\n",
      "      üìÇ Genres: Phim G√¢y C·∫•n, Phim H√¨nh S·ª±, Phim H√†nh ƒê·ªông, Phim Ch√≠nh K·ªãch\n",
      "      üé¨ Director's other works: H·ªë ƒêen T·ª≠ Th·∫ßn, K·∫ª C·∫Øp Gi·∫•c M∆°, K·ªµ Sƒ© B√≥ng ƒê√™m\n",
      "\n",
      "   3. Ng∆∞·ªùi D∆°i B·∫Øt ƒê·∫ßu (2005)\n",
      "      üé• Director: Christopher Nolan\n",
      "      üë• Cast: Michael Caine, Christian Bale, Liam Neeson\n",
      "      üìÇ Genres: Phim H√¨nh S·ª±, Phim H√†nh ƒê·ªông, Phim Ch√≠nh K·ªãch\n",
      "      üé¨ Director's other works: H·ªë ƒêen T·ª≠ Th·∫ßn, K·∫ª C·∫Øp Gi·∫•c M∆°, K·ªµ Sƒ© B√≥ng ƒê√™m\n",
      "\n",
      "======================================================================\n",
      "üìä COMPARISON SUMMARY\n",
      "======================================================================\n",
      "\n",
      "‚ö° Performance:\n",
      "   ‚Ä¢ Vector only:  308.3ms\n",
      "   ‚Ä¢ Graph only:   310.5ms\n",
      "   ‚Ä¢ Hybrid:       849.5ms\n",
      "\n",
      "üéØ Best Use Cases:\n",
      "   ‚Ä¢ Vector Search:  Semantic understanding, natural language queries\n",
      "   ‚Ä¢ Graph Search:   Structured queries, relationships, filtering\n",
      "   ‚Ä¢ Hybrid:         Best of both - semantic + contextual enrichment\n",
      "\n",
      "üí° Recommendation:\n",
      "   For production, use HYBRID approach for:\n",
      "   ‚Ä¢ More accurate semantic matching (vector)\n",
      "   ‚Ä¢ Rich contextual information (graph)\n",
      "   ‚Ä¢ Better user experience with detailed results\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# üî¨ Hybrid Search Comparison: Vector vs Graph vs Combined\n",
    "\n",
    "query = \"Phim h√†nh ƒë·ªông c·ªßa Christopher Nolan\"  # Change this to test different queries\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"üî¨ HYBRID SEARCH COMPARISON\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nüîç Query: \\\"{query}\\\"\\n\")\n",
    "\n",
    "results = {}\n",
    "vector_time = 0  # Initialize to avoid NameError\n",
    "graph_time = 0\n",
    "hybrid_time = 0\n",
    "hits = []  # Initialize empty list\n",
    "\n",
    "# ===== 1. VECTOR SEARCH =====\n",
    "print(\"1Ô∏è‚É£ VECTOR SEARCH (Semantic Similarity)\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "try:\n",
    "    if 'q_client' not in locals() and 'qdrant_client' in locals():\n",
    "        q_client = qdrant_client\n",
    "    \n",
    "    if 'embed_model' not in locals():\n",
    "        from sentence_transformers import SentenceTransformer\n",
    "        embed_model = SentenceTransformer('paraphrase-multilingual-mpnet-base-v2')\n",
    "    \n",
    "    import time\n",
    "    start = time.time()\n",
    "    \n",
    "    query_vector = embed_model.encode(query).tolist()\n",
    "    \n",
    "    # Try new API first, fall back to old API\n",
    "    try:\n",
    "        # New API (qdrant-client >= 1.7.0)\n",
    "        from qdrant_client.models import SearchRequest\n",
    "        hits = q_client.search(\n",
    "            collection_name=COLLECTION_NAME,\n",
    "            query_vector=query_vector,\n",
    "            limit=5\n",
    "        )\n",
    "    except (AttributeError, TypeError):\n",
    "        # Old API or different method name\n",
    "        try:\n",
    "            hits = q_client.query_points(\n",
    "                collection_name=COLLECTION_NAME,\n",
    "                query=query_vector,\n",
    "                limit=5\n",
    "            ).points\n",
    "        except:\n",
    "            # Fallback: try with search_points\n",
    "            search_result = q_client.search_points(\n",
    "                collection_name=COLLECTION_NAME,\n",
    "                vector=query_vector,\n",
    "                limit=5\n",
    "            )\n",
    "            hits = search_result if isinstance(search_result, list) else search_result.points\n",
    "    \n",
    "    vector_time = (time.time() - start) * 1000\n",
    "    \n",
    "    print(f\"‚ö° Time: {vector_time:.1f}ms | Found: {len(hits)} movies\\n\")\n",
    "    \n",
    "    vector_results = []\n",
    "    for i, hit in enumerate(hits, 1):\n",
    "        # Handle different response structures\n",
    "        payload = hit.payload if hasattr(hit, 'payload') else hit\n",
    "        title = payload.get('title', 'N/A')\n",
    "        year = payload.get('year', 'N/A')\n",
    "        score = hit.score if hasattr(hit, 'score') else 0\n",
    "        vector_results.append((title, year, score))\n",
    "        print(f\"   {i}. {title} ({year}) - Score: {score:.3f}\")\n",
    "    \n",
    "    results['vector'] = vector_results\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"   ‚ùå Failed: {str(e)[:150]}\")\n",
    "    print(f\"   üí° Tip: Try running Cell 7 for vector search instead\")\n",
    "    results['vector'] = []\n",
    "\n",
    "# ===== 2. GRAPH SEARCH =====\n",
    "print(\"\\n\\n2Ô∏è‚É£ GRAPH SEARCH (Structured Query)\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "try:\n",
    "    # Check if n_driver exists and reconnect if needed\n",
    "    driver_needs_reconnect = False\n",
    "    \n",
    "    if 'n_driver' not in locals():\n",
    "        driver_needs_reconnect = True\n",
    "    else:\n",
    "        try:\n",
    "            with n_driver.session() as test_session:\n",
    "                test_session.run(\"RETURN 1\")\n",
    "        except Exception:\n",
    "            driver_needs_reconnect = True\n",
    "            try:\n",
    "                n_driver.close()\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    if driver_needs_reconnect:\n",
    "        from neo4j import GraphDatabase\n",
    "        n_driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD))\n",
    "    \n",
    "    # Parse query for graph patterns (simple example)\n",
    "    # In real implementation, use NER/RE from query_processor.py\n",
    "    \n",
    "    import time\n",
    "    start = time.time()\n",
    "    \n",
    "    # Example: Search for director + genre\n",
    "    cypher = \"\"\"\n",
    "    MATCH (d:Person)-[:DIRECTED]->(m:Movie)-[:BELONGS_TO]->(g:Genre)\n",
    "    WHERE toLower(d.name) CONTAINS toLower($name)\n",
    "       OR toLower(m.title) CONTAINS toLower($title)\n",
    "       OR toLower(g.name) CONTAINS toLower($genre)\n",
    "    RETURN DISTINCT m.title as title, m.year as year, m.rating as rating,\n",
    "           d.name as director, collect(DISTINCT g.name)[..3] as genres\n",
    "    ORDER BY m.rating DESC\n",
    "    LIMIT 5\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract keywords from query (simple approach)\n",
    "    keywords = query.lower()\n",
    "    \n",
    "    with n_driver.session() as session:\n",
    "        result = session.run(cypher, {\n",
    "            'name': 'nolan' if 'nolan' in keywords else '',\n",
    "            'title': keywords,\n",
    "            'genre': 'action' if 'h√†nh ƒë·ªông' in keywords or 'action' in keywords else ''\n",
    "        })\n",
    "        records = list(result)\n",
    "    \n",
    "    graph_time = (time.time() - start) * 1000\n",
    "    \n",
    "    print(f\"‚ö° Time: {graph_time:.1f}ms | Found: {len(records)} movies\\n\")\n",
    "    \n",
    "    graph_results = []\n",
    "    for i, record in enumerate(records, 1):\n",
    "        title = record['title']\n",
    "        year = record['year']\n",
    "        director = record.get('director', 'Unknown')\n",
    "        rating = record.get('rating', 0)\n",
    "        graph_results.append((title, year, rating))\n",
    "        print(f\"   {i}. {title} ({year}) - Director: {director} - Rating: {rating}/10\")\n",
    "    \n",
    "    results['graph'] = graph_results\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"   ‚ùå Failed: {str(e)[:150]}\")\n",
    "    print(f\"   üí° Tip: Try running Cell 8 for graph search instead\")\n",
    "    results['graph'] = []\n",
    "\n",
    "# ===== 3. HYBRID APPROACH =====\n",
    "print(\"\\n\\n3Ô∏è‚É£ HYBRID APPROACH (Vector + Graph Enrichment)\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "try:\n",
    "    if not hits or len(hits) == 0:\n",
    "        print(\"   ‚ö†Ô∏è Skipped: No vector search results available\")\n",
    "        print(\"   üí° Vector search must succeed for hybrid approach\")\n",
    "    else:\n",
    "        # Step 1: Get IDs from vector search\n",
    "        vector_ids = []\n",
    "        for hit in hits[:3]:  # Top 3\n",
    "            payload = hit.payload if hasattr(hit, 'payload') else hit\n",
    "            tmdb_id = payload.get('tmdb_id')\n",
    "            if tmdb_id:\n",
    "                vector_ids.append(tmdb_id)\n",
    "        \n",
    "        if not vector_ids:\n",
    "            print(\"   ‚ö†Ô∏è No TMDB IDs found in vector results\")\n",
    "        else:\n",
    "            # Step 2: Enrich with graph context\n",
    "            import time\n",
    "            start = time.time()\n",
    "            \n",
    "            enrich_cypher = \"\"\"\n",
    "            MATCH (m:Movie) WHERE m.id IN $ids\n",
    "            OPTIONAL MATCH (d:Person)-[:DIRECTED]->(m)\n",
    "            OPTIONAL MATCH (a:Person)-[:ACTED_IN]->(m)\n",
    "            OPTIONAL MATCH (m)-[:BELONGS_TO]->(g:Genre)\n",
    "            OPTIONAL MATCH (d)-[:DIRECTED]->(other:Movie) WHERE other.id <> m.id\n",
    "            RETURN m.title as title, m.year as year, m.rating as rating,\n",
    "                   d.name as director, \n",
    "                   collect(DISTINCT a.name)[..4] as cast,\n",
    "                   collect(DISTINCT g.name) as genres,\n",
    "                   collect(DISTINCT other.title)[..3] as director_other_works\n",
    "            \"\"\"\n",
    "            \n",
    "            with n_driver.session() as session:\n",
    "                result = session.run(enrich_cypher, {'ids': vector_ids})\n",
    "                enriched = list(result)\n",
    "            \n",
    "            hybrid_time = vector_time + (time.time() - start) * 1000\n",
    "            \n",
    "            print(f\"‚ö° Time: {hybrid_time:.1f}ms | Enriched: {len(enriched)} movies\\n\")\n",
    "            \n",
    "            if enriched:\n",
    "                for i, record in enumerate(enriched, 1):\n",
    "                    print(f\"   {i}. {record['title']} ({record['year']})\")\n",
    "                    if record.get('director'):\n",
    "                        print(f\"      üé• Director: {record['director']}\")\n",
    "                    if record.get('cast'):\n",
    "                        print(f\"      üë• Cast: {', '.join(record['cast'][:3])}\")\n",
    "                    if record.get('genres'):\n",
    "                        print(f\"      üìÇ Genres: {', '.join(record['genres'])}\")\n",
    "                    if record.get('director_other_works'):\n",
    "                        print(f\"      üé¨ Director's other works: {', '.join(record['director_other_works'])}\")\n",
    "                    print()\n",
    "            else:\n",
    "                print(\"   ‚ö†Ô∏è No enriched results (movies might not be in graph DB)\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"   ‚ùå Failed: {str(e)[:150]}\")\n",
    "\n",
    "# ===== COMPARISON SUMMARY =====\n",
    "print(\"=\" * 70)\n",
    "print(\"üìä COMPARISON SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\n‚ö° Performance:\")\n",
    "if vector_time > 0:\n",
    "    print(f\"   ‚Ä¢ Vector only:  {vector_time:.1f}ms\")\n",
    "else:\n",
    "    print(f\"   ‚Ä¢ Vector only:  N/A (failed)\")\n",
    "\n",
    "if graph_time > 0:\n",
    "    print(f\"   ‚Ä¢ Graph only:   {graph_time:.1f}ms\")\n",
    "else:\n",
    "    print(f\"   ‚Ä¢ Graph only:   N/A\")\n",
    "\n",
    "if hybrid_time > 0:\n",
    "    print(f\"   ‚Ä¢ Hybrid:       {hybrid_time:.1f}ms\")\n",
    "else:\n",
    "    print(f\"   ‚Ä¢ Hybrid:       N/A (requires vector search)\")\n",
    "\n",
    "print(f\"\\nüéØ Best Use Cases:\")\n",
    "print(f\"   ‚Ä¢ Vector Search:  Semantic understanding, natural language queries\")\n",
    "print(f\"   ‚Ä¢ Graph Search:   Structured queries, relationships, filtering\")\n",
    "print(f\"   ‚Ä¢ Hybrid:         Best of both - semantic + contextual enrichment\")\n",
    "\n",
    "print(\"\\nüí° Recommendation:\")\n",
    "print(\"   For production, use HYBRID approach for:\")\n",
    "print(\"   ‚Ä¢ More accurate semantic matching (vector)\")\n",
    "print(\"   ‚Ä¢ Rich contextual information (graph)\")\n",
    "print(\"   ‚Ä¢ Better user experience with detailed results\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d5c8c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
