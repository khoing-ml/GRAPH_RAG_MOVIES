import json
import os
from qdrant_client.models import PointStruct
from .llm_service import GeminiService
from .vector_db import QdrantService
from .graph_db import Neo4jService
from tqdm import tqdm

DATA_FILE = "notebooks/google_books_10k.json"

def run_ingestion():
    if not os.path.exists(DATA_FILE):
        print(f"L·ªói: Kh√¥ng t√¨m th·∫•y file '{DATA_FILE}'. H√£y ch·∫°y notebook crawl d·ªØ li·ªáu tr∆∞·ªõc!")
        return

    print(f"üìÇ ƒêang ƒë·ªçc d·ªØ li·ªáu t·ª´ {DATA_FILE}...")
    with open(DATA_FILE, "r", encoding="utf-8") as f:
        raw_books = json.load(f)

    if not raw_books:
        print("File d·ªØ li·ªáu r·ªóng!")
        return

    print(f"üöÄ B·∫Øt ƒë·∫ßu x·ª≠ l√Ω {len(raw_books)} cu·ªën s√°ch...")
    
    llm = GeminiService()
    vectordb = QdrantService()
    graphdb = Neo4jService()

    batch_points = []
    batch_size = 20 # Gom nh√≥m ƒë·ªÉ insert v√†o Qdrant cho nhanh

    for book in tqdm(raw_books, desc="Ingesting"):
        try:
            title = book.get("title", "No Title")
            summary = book.get("summary", "")
            
            # N·∫øu kh√¥ng c√≥ n·ªôi dung t√≥m t·∫Øt, b·ªè qua v√¨ kh√¥ng t·∫°o vector ƒë∆∞·ª£c
            if not summary: 
                continue

            # 1. T·∫°o Vector Embedding (Title + Summary + Genre)
            text_to_embed = f"Title: {title}. Genre: {book.get('genre')}. Summary: {summary}"
            embedding = llm.get_embedding(text_to_embed)
            
            if embedding:
                # T·∫°o ID s·ªë nguy√™n d∆∞∆°ng cho Qdrant t·ª´ chu·ªói ID g·ªëc
                point_id = hash(book["id"]) & ((1<<64)-1)

                batch_points.append(PointStruct(
                    id=point_id,
                    vector=embedding,
                    payload={
                        "book_id": book["id"],  
                        "title": title,
                        "language": book.get("language", "en")
                    }
                ))

            # 2. L∆∞u v√†o Graph Database
            graphdb.add_book_data(book)

            # Insert Batch n·∫øu ƒë·∫ßy
            if len(batch_points) >= batch_size:
                vectordb.upsert_vectors(batch_points)
                batch_points = []

        except Exception as e:
            print(f"L·ªói khi x·ª≠ l√Ω s√°ch '{title}': {e}")

    # Insert n·ªët s·ªë c√≤n l·∫°i
    if batch_points:
        vectordb.upsert_vectors(batch_points)
        
    graphdb.close()
    print("HO√ÄN T·∫§T N·∫†P D·ªÆ LI·ªÜU!")

if __name__ == "__main__":
    run_ingestion()