from .llm_service import GeminiService
from .vector_db import QdrantService
from .graph_db import Neo4jService

class GraphRAG:
    def __init__(self):
        self.llm = GeminiService()
        self.vectordb = QdrantService()
        self.graphdb = Neo4jService()

    def query(self, user_question):
        print(f"\nüîé ƒêang ph√¢n t√≠ch c√¢u h·ªèi: '{user_question}'...")
        
        # B∆Ø·ªöC 1: T√¨m ki·∫øm Vector (Semantic Search)
        # T√¨m c√°c ƒëo·∫°n t√≥m t·∫Øt s√°ch c√≥ √Ω nghƒ©a t∆∞∆°ng ƒë·ªìng
        query_vec = self.llm.get_embedding(user_question, task_type="retrieval_query")
        
        if not query_vec:
            return "Xin l·ªói, h·ªá th·ªëng ƒëang b·∫≠n, kh√¥ng th·ªÉ t·∫°o vector."

        search_results = self.vectordb.search(query_vec, top_k=4) # L·∫•y top 4
        
        if not search_results:
            return "R·∫•t ti·∫øc, t√¥i kh√¥ng t√¨m th·∫•y cu·ªën s√°ch n√†o ph√π h·ª£p trong c∆° s·ªü d·ªØ li·ªáu."

        # L·∫•y ra danh s√°ch ID s√°ch t√¨m ƒë∆∞·ª£c
        found_ids = [hit.payload['book_id'] for hit in search_results]
        print(f"‚úÖ Vector DB t√¨m th·∫•y {len(found_ids)} s√°ch ti·ªÅm nƒÉng.")

        # B∆Ø·ªöC 2: Truy v·∫•n Graph (Context Enrichment)
        # D√πng ID ƒë·ªÉ l·∫•y th√™m th√¥ng tin c·∫•u tr√∫c (T√°c gi·∫£, quan h·ªá...)
        print("üï∏Ô∏è  ƒêang truy v·∫•n Graph Database...")
        graph_context = self.graphdb.get_graph_context(found_ids)
        
        if not graph_context:
            graph_context = "Kh√¥ng t√¨m th·∫•y th√¥ng tin chi ti·∫øt trong Graph DB."

        # B∆Ø·ªöC 3: T·ªïng h·ª£p c√¢u tr·∫£ l·ªùi b·∫±ng LLM
        print("ü§ñ ƒêang t·ªïng h·ª£p c√¢u tr·∫£ l·ªùi...")
        answer = self.llm.generate_answer(graph_context, user_question)
        return answer

    def close(self):
        self.graphdb.close()